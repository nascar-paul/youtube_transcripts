[
    {
        "text": "every exponential is a sigmo looking",
        "start": 0.199,
        "duration": 4.321
    },
    {
        "text": "backwards um and so this is exactly what",
        "start": 2.36,
        "duration": 4.28
    },
    {
        "text": "happened with airplane speeds um I think",
        "start": 4.52,
        "duration": 5.28
    },
    {
        "text": "in the early 1970s or late 1960s people",
        "start": 6.64,
        "duration": 5.56
    },
    {
        "text": "were booking flights to the Moon based",
        "start": 9.8,
        "duration": 4.4
    },
    {
        "text": "on the increasing trend of airplane",
        "start": 12.2,
        "duration": 4.24
    },
    {
        "text": "speeds at the time and then essentially",
        "start": 14.2,
        "duration": 3.96
    },
    {
        "text": "all of a sudden these increasing",
        "start": 16.44,
        "duration": 4.28
    },
    {
        "text": "airplane speeds came to a halt um we had",
        "start": 18.16,
        "duration": 4.84
    },
    {
        "text": "the saturated around the speeds that we",
        "start": 20.72,
        "duration": 5.04
    },
    {
        "text": "have today one exponential which hasn't",
        "start": 23.0,
        "duration": 5.279
    },
    {
        "text": "saturated yet is the cost of search API",
        "start": 25.76,
        "duration": 5.439
    },
    {
        "text": "access but there's one ception the brave",
        "start": 28.279,
        "duration": 5.761
    },
    {
        "text": "search API is an affordable independent",
        "start": 31.199,
        "duration": 5.481
    },
    {
        "text": "search solution the brave search index",
        "start": 34.04,
        "duration": 5.72
    },
    {
        "text": "covers over 20 billion web pages without",
        "start": 36.68,
        "duration": 6.039
    },
    {
        "text": "the big Tech biases or the extortion at",
        "start": 39.76,
        "duration": 5.6
    },
    {
        "text": "recent price hikes so what makes it",
        "start": 42.719,
        "duration": 5.241
    },
    {
        "text": "unique well it's powered by real human",
        "start": 45.36,
        "duration": 4.92
    },
    {
        "text": "anonymized web page visits so they're",
        "start": 47.96,
        "duration": 4.64
    },
    {
        "text": "filtering out all of the junk data and",
        "start": 50.28,
        "duration": 5.079
    },
    {
        "text": "it's updated daily with tens of millions",
        "start": 52.6,
        "duration": 5.919
    },
    {
        "text": "of new web pages Brave is perfect for um",
        "start": 55.359,
        "duration": 5.281
    },
    {
        "text": "AI model training and ret augmented",
        "start": 58.519,
        "duration": 5.0
    },
    {
        "text": "generation use cases the data is sourced",
        "start": 60.64,
        "duration": 5.479
    },
    {
        "text": "ethically and the prices are Developer",
        "start": 63.519,
        "duration": 5.001
    },
    {
        "text": "friendly if you want representative data",
        "start": 66.119,
        "duration": 4.481
    },
    {
        "text": "and upto-date information the brave",
        "start": 68.52,
        "duration": 4.72
    },
    {
        "text": "search API offers both so go to",
        "start": 70.6,
        "duration": 3.879
    },
    {
        "text": "brave.com",
        "start": 73.24,
        "duration": 4.48
    },
    {
        "text": "API check it out they give you 2,000",
        "start": 74.479,
        "duration": 5.441
    },
    {
        "text": "free queries every single month so you",
        "start": 77.72,
        "duration": 3.759
    },
    {
        "text": "can go on there and you can see how good",
        "start": 79.92,
        "duration": 4.839
    },
    {
        "text": "this index is enjoy the show I'm Sayes",
        "start": 81.479,
        "duration": 5.121
    },
    {
        "text": "Kapur I'm a PhD candidate and a",
        "start": 84.759,
        "duration": 3.68
    },
    {
        "text": "researcher at Princeton University",
        "start": 86.6,
        "duration": 4.72
    },
    {
        "text": "Center for it policy um and I'm",
        "start": 88.439,
        "duration": 4.521
    },
    {
        "text": "currently finishing up my PhD at the",
        "start": 91.32,
        "duration": 3.799
    },
    {
        "text": "department of computer science and",
        "start": 92.96,
        "duration": 3.32
    },
    {
        "text": "you're working on this really",
        "start": 95.119,
        "duration": 3.401
    },
    {
        "text": "interesting book right yeah the book is",
        "start": 96.28,
        "duration": 4.76
    },
    {
        "text": "called AI snake oil and uh we try to",
        "start": 98.52,
        "duration": 4.4
    },
    {
        "text": "delineate between applications of AI",
        "start": 101.04,
        "duration": 4.439
    },
    {
        "text": "that work from those that don't and we",
        "start": 102.92,
        "duration": 4.199
    },
    {
        "text": "basically want to offer readers a way to",
        "start": 105.479,
        "duration": 3.6
    },
    {
        "text": "cut through the hype yeah I've been",
        "start": 107.119,
        "duration": 3.201
    },
    {
        "text": "looking forward to this book for months",
        "start": 109.079,
        "duration": 3.04
    },
    {
        "text": "now so um hopefully I can get a",
        "start": 110.32,
        "duration": 4.0
    },
    {
        "text": "pre-release copy and I'd love to do",
        "start": 112.119,
        "duration": 3.6
    },
    {
        "text": "another conversation about that cuz I'm",
        "start": 114.32,
        "duration": 3.36
    },
    {
        "text": "really excited about that absolutely",
        "start": 115.719,
        "duration": 3.921
    },
    {
        "text": "amazing okay so um I I want to talk",
        "start": 117.68,
        "duration": 3.799
    },
    {
        "text": "about your um article that that you just",
        "start": 119.64,
        "duration": 3.839
    },
    {
        "text": "released on on your substack but just",
        "start": 121.479,
        "duration": 4.0
    },
    {
        "text": "before we get there I mean how seriously",
        "start": 123.479,
        "duration": 4.161
    },
    {
        "text": "should the government take the threat of",
        "start": 125.479,
        "duration": 5.041
    },
    {
        "text": "existential risk from AI uh so the",
        "start": 127.64,
        "duration": 5.239
    },
    {
        "text": "threat of existential risk I think is",
        "start": 130.52,
        "duration": 4.16
    },
    {
        "text": "sort of a once in a-lifetime event in",
        "start": 132.879,
        "duration": 4.121
    },
    {
        "text": "some sense and to some extent I think",
        "start": 134.68,
        "duration": 4.48
    },
    {
        "text": "we've seen policy makers adapt to claims",
        "start": 137.0,
        "duration": 4.239
    },
    {
        "text": "about existential risk both from",
        "start": 139.16,
        "duration": 4.04
    },
    {
        "text": "prominent AI researchers but also from",
        "start": 141.239,
        "duration": 3.921
    },
    {
        "text": "communities such as the AI safety",
        "start": 143.2,
        "duration": 3.399
    },
    {
        "text": "Community the effective altruist",
        "start": 145.16,
        "duration": 3.28
    },
    {
        "text": "community and so to some extent I think",
        "start": 146.599,
        "duration": 4.64
    },
    {
        "text": "the response is reasonable um it's a",
        "start": 148.44,
        "duration": 4.64
    },
    {
        "text": "event that can only happen once so we",
        "start": 151.239,
        "duration": 3.64
    },
    {
        "text": "only have one chance to get it right to",
        "start": 153.08,
        "duration": 4.4
    },
    {
        "text": "some extent and in the article we uh try",
        "start": 154.879,
        "duration": 4.64
    },
    {
        "text": "to go over what the arguments for",
        "start": 157.48,
        "duration": 4.32
    },
    {
        "text": "existential risk are and uh and how",
        "start": 159.519,
        "duration": 3.521
    },
    {
        "text": "seriously we should be taking these",
        "start": 161.8,
        "duration": 3.359
    },
    {
        "text": "arguments um and we in particular look",
        "start": 163.04,
        "duration": 4.0
    },
    {
        "text": "at one of these arguments which is the",
        "start": 165.159,
        "duration": 4.281
    },
    {
        "text": "probability of Doom or P Doom which has",
        "start": 167.04,
        "duration": 4.72
    },
    {
        "text": "become like rampant not just in the Tech",
        "start": 169.44,
        "duration": 3.84
    },
    {
        "text": "Community but also in the policymaking",
        "start": 171.76,
        "duration": 3.64
    },
    {
        "text": "spaces in the last couple of years",
        "start": 173.28,
        "duration": 3.599
    },
    {
        "text": "interesting so you made the argument",
        "start": 175.4,
        "duration": 4.08
    },
    {
        "text": "essentially that these risk um you know",
        "start": 176.879,
        "duration": 4.481
    },
    {
        "text": "probabil ities are too unreliable to",
        "start": 179.48,
        "duration": 5.08
    },
    {
        "text": "inform policy can you elaborate on that",
        "start": 181.36,
        "duration": 5.72
    },
    {
        "text": "yes um so when we're coming up with",
        "start": 184.56,
        "duration": 4.44
    },
    {
        "text": "probabilities for any event I think",
        "start": 187.08,
        "duration": 4.12
    },
    {
        "text": "there are basically only three ways to",
        "start": 189.0,
        "duration": 4.36
    },
    {
        "text": "go about it we can come about it",
        "start": 191.2,
        "duration": 4.44
    },
    {
        "text": "inductively that is we look at past",
        "start": 193.36,
        "duration": 4.08
    },
    {
        "text": "events of a similar sort that have",
        "start": 195.64,
        "duration": 3.8
    },
    {
        "text": "happened we can come about it",
        "start": 197.44,
        "duration": 4.4
    },
    {
        "text": "deductively that is we have a theory for",
        "start": 199.44,
        "duration": 4.12
    },
    {
        "text": "how the world works and then we apply",
        "start": 201.84,
        "duration": 4.6
    },
    {
        "text": "the theory to make predictions or um as",
        "start": 203.56,
        "duration": 4.599
    },
    {
        "text": "has become the norm in the AI Community",
        "start": 206.44,
        "duration": 3.799
    },
    {
        "text": "we can come about it subjectively now",
        "start": 208.159,
        "duration": 3.481
    },
    {
        "text": "let's set that one aside for the moment",
        "start": 210.239,
        "duration": 2.64
    },
    {
        "text": "and let's dive into inductive and",
        "start": 211.64,
        "duration": 3.599
    },
    {
        "text": "deductive probabilities first um so in",
        "start": 212.879,
        "duration": 4.401
    },
    {
        "text": "terms of inductive probability um you",
        "start": 215.239,
        "duration": 3.761
    },
    {
        "text": "can come up with great probability",
        "start": 217.28,
        "duration": 3.84
    },
    {
        "text": "estimates for the risk of let's say car",
        "start": 219.0,
        "duration": 5.56
    },
    {
        "text": "crashes by looking at um like a person",
        "start": 221.12,
        "duration": 4.88
    },
    {
        "text": "of a certain type who drives a certain",
        "start": 224.56,
        "duration": 2.599
    },
    {
        "text": "type of car lives in a certain",
        "start": 226.0,
        "duration": 3.68
    },
    {
        "text": "neighborhood Etc insurance companies",
        "start": 227.159,
        "duration": 4.92
    },
    {
        "text": "regularly price uh products like insur",
        "start": 229.68,
        "duration": 4.72
    },
    {
        "text": "car insurance premiums and I think more",
        "start": 232.079,
        "duration": 4.041
    },
    {
        "text": "or less that seems to work well I mean",
        "start": 234.4,
        "duration": 3.559
    },
    {
        "text": "there are some nuances about bias and",
        "start": 236.12,
        "duration": 4.08
    },
    {
        "text": "risks of discrimination but apart from",
        "start": 237.959,
        "duration": 4.56
    },
    {
        "text": "that you know like let's say if a car",
        "start": 240.2,
        "duration": 5.319
    },
    {
        "text": "insurance prediction is 20% off uh that",
        "start": 242.519,
        "duration": 5.881
    },
    {
        "text": "seems all right right um we cannot do",
        "start": 245.519,
        "duration": 5.881
    },
    {
        "text": "that for AI risk simply because there is",
        "start": 248.4,
        "duration": 5.24
    },
    {
        "text": "no past evidence for this type of work",
        "start": 251.4,
        "duration": 4.6
    },
    {
        "text": "we don't have a reference class so to",
        "start": 253.64,
        "duration": 4.52
    },
    {
        "text": "say and so any probability numbers that",
        "start": 256.0,
        "duration": 5.32
    },
    {
        "text": "we come up with based on past events are",
        "start": 258.16,
        "duration": 5.479
    },
    {
        "text": "extremely speculative now to be clear",
        "start": 261.32,
        "duration": 5.0
    },
    {
        "text": "this reference class is a spectrum so",
        "start": 263.639,
        "duration": 5.481
    },
    {
        "text": "certain things can happen multiple times",
        "start": 266.32,
        "duration": 4.76
    },
    {
        "text": "many millions ions of times and we have",
        "start": 269.12,
        "duration": 4.76
    },
    {
        "text": "extremely um precise reference grasses",
        "start": 271.08,
        "duration": 5.559
    },
    {
        "text": "if you will so like when you toss a coin",
        "start": 273.88,
        "duration": 4.599
    },
    {
        "text": "uh we have a very clear reference class",
        "start": 276.639,
        "duration": 3.641
    },
    {
        "text": "and we can predict that um the",
        "start": 278.479,
        "duration": 3.921
    },
    {
        "text": "probability of a fair coin will be let's",
        "start": 280.28,
        "duration": 4.88
    },
    {
        "text": "say 50% uh Landing as heads and 50%",
        "start": 282.4,
        "duration": 5.639
    },
    {
        "text": "Tails um we might have reference classes",
        "start": 285.16,
        "duration": 4.4
    },
    {
        "text": "that are somewhat more wague like the",
        "start": 288.039,
        "duration": 3.681
    },
    {
        "text": "car insurance example and then in",
        "start": 289.56,
        "duration": 4.88
    },
    {
        "text": "typical probability estimation of events",
        "start": 291.72,
        "duration": 4.56
    },
    {
        "text": "um the extreme end of the spectrum is",
        "start": 294.44,
        "duration": 4.08
    },
    {
        "text": "things like um geopolitical events where",
        "start": 296.28,
        "duration": 4.479
    },
    {
        "text": "you have the risk of War um and the",
        "start": 298.52,
        "duration": 4.959
    },
    {
        "text": "reference class is um past events of a",
        "start": 300.759,
        "duration": 4.521
    },
    {
        "text": "similar nature so past Wars that have",
        "start": 303.479,
        "duration": 5.241
    },
    {
        "text": "broken out um past fams that have led to",
        "start": 305.28,
        "duration": 6.479
    },
    {
        "text": "political instability and so on now",
        "start": 308.72,
        "duration": 5.199
    },
    {
        "text": "compared to this entire spectrum of",
        "start": 311.759,
        "duration": 4.921
    },
    {
        "text": "reference classes AI risk is maybe",
        "start": 313.919,
        "duration": 4.441
    },
    {
        "text": "completely outside the Spectrum or at",
        "start": 316.68,
        "duration": 3.72
    },
    {
        "text": "like an extreme end of the spectrum to",
        "start": 318.36,
        "duration": 4.24
    },
    {
        "text": "the extent that a reference class just",
        "start": 320.4,
        "duration": 4.639
    },
    {
        "text": "does not exist now people have tried to",
        "start": 322.6,
        "duration": 3.96
    },
    {
        "text": "come up with reference classes and I'll",
        "start": 325.039,
        "duration": 3.641
    },
    {
        "text": "I'll share some of them just to so show",
        "start": 326.56,
        "duration": 4.04
    },
    {
        "text": "how absurd the these reference classes",
        "start": 328.68,
        "duration": 4.359
    },
    {
        "text": "can be one example is the risk of",
        "start": 330.6,
        "duration": 5.439
    },
    {
        "text": "various animals going extent um another",
        "start": 333.039,
        "duration": 5.481
    },
    {
        "text": "reference class is past um sort of",
        "start": 336.039,
        "duration": 4.641
    },
    {
        "text": "changes to the Earth's atmosphere past",
        "start": 338.52,
        "duration": 5.32
    },
    {
        "text": "waves of Extinction that we've seen and",
        "start": 340.68,
        "duration": 5.2
    },
    {
        "text": "hopefully it's clear how very different",
        "start": 343.84,
        "duration": 4.479
    },
    {
        "text": "all of these types of risks are compared",
        "start": 345.88,
        "duration": 4.96
    },
    {
        "text": "to the risk of us losing control over AI",
        "start": 348.319,
        "duration": 4.481
    },
    {
        "text": "or power seeking Behavior emerging in",
        "start": 350.84,
        "duration": 3.72
    },
    {
        "text": "super intelligent systems or all of the",
        "start": 352.8,
        "duration": 4.36
    },
    {
        "text": "other hypothesis so it is on this basis",
        "start": 354.56,
        "duration": 4.72
    },
    {
        "text": "that we reject the idea that we can come",
        "start": 357.16,
        "duration": 3.879
    },
    {
        "text": "up with reference classes and therefore",
        "start": 359.28,
        "duration": 3.08
    },
    {
        "text": "we can come up with inductive",
        "start": 361.039,
        "duration": 3.72
    },
    {
        "text": "probability estimates um of the risks of",
        "start": 362.36,
        "duration": 5.36
    },
    {
        "text": "a doom so that leaves us with deductive",
        "start": 364.759,
        "duration": 5.241
    },
    {
        "text": "estimates of probability um deductive",
        "start": 367.72,
        "duration": 3.879
    },
    {
        "text": "estimates are those where we have a",
        "start": 370.0,
        "duration": 4.0
    },
    {
        "text": "theory that we have validated in some",
        "start": 371.599,
        "duration": 4.681
    },
    {
        "text": "real world setting and we seek to apply",
        "start": 374.0,
        "duration": 4.96
    },
    {
        "text": "it to this other real world setting um",
        "start": 376.28,
        "duration": 4.44
    },
    {
        "text": "and we have faith in the theory simply",
        "start": 378.96,
        "duration": 3.72
    },
    {
        "text": "because of it being validated and us",
        "start": 380.72,
        "duration": 3.96
    },
    {
        "text": "making assumptions about the scope of",
        "start": 382.68,
        "duration": 3.72
    },
    {
        "text": "this Theory and now this is all a little",
        "start": 384.68,
        "duration": 4.959
    },
    {
        "text": "bit abstract so let's get concrete one",
        "start": 386.4,
        "duration": 6.239
    },
    {
        "text": "example of X risk that's not from AI is",
        "start": 389.639,
        "duration": 5.641
    },
    {
        "text": "existential risks from asteroid impact",
        "start": 392.639,
        "duration": 5.56
    },
    {
        "text": "so we might be concerned that um when an",
        "start": 395.28,
        "duration": 5.319
    },
    {
        "text": "asteroid of a sufficiently large size",
        "start": 398.199,
        "duration": 4.201
    },
    {
        "text": "let's say collides with the Earth uh",
        "start": 400.599,
        "duration": 3.72
    },
    {
        "text": "there would be enough energy generated",
        "start": 402.4,
        "duration": 3.88
    },
    {
        "text": "that it could sort of clog up the",
        "start": 404.319,
        "duration": 3.521
    },
    {
        "text": "atmosphere and block off all",
        "start": 406.28,
        "duration": 4.039
    },
    {
        "text": "agricultural production now how can we",
        "start": 407.84,
        "duration": 4.56
    },
    {
        "text": "come up with a deductive theory for this",
        "start": 410.319,
        "duration": 4.401
    },
    {
        "text": "well we have evidence from a large",
        "start": 412.4,
        "duration": 4.68
    },
    {
        "text": "number of smaller asteroid hits as to",
        "start": 414.72,
        "duration": 4.159
    },
    {
        "text": "what happens when an asteroid collides",
        "start": 417.08,
        "duration": 3.799
    },
    {
        "text": "with the Earth um and based on this",
        "start": 418.879,
        "duration": 4.0
    },
    {
        "text": "Theory we can sort of extrapolate to",
        "start": 420.879,
        "duration": 4.681
    },
    {
        "text": "what would happen um when a large enough",
        "start": 422.879,
        "duration": 5.201
    },
    {
        "text": "asteroid hits the Earth and again and",
        "start": 425.56,
        "duration": 4.56
    },
    {
        "text": "drawing from other theory about what",
        "start": 428.08,
        "duration": 3.799
    },
    {
        "text": "would happen and how much energy would",
        "start": 430.12,
        "duration": 3.72
    },
    {
        "text": "be needed to sort of block off the",
        "start": 431.879,
        "duration": 3.88
    },
    {
        "text": "production of agriculture in the world",
        "start": 433.84,
        "duration": 3.52
    },
    {
        "text": "uh we can then come up with an estimate",
        "start": 435.759,
        "duration": 3.961
    },
    {
        "text": "for how big an asteroid needs to be um",
        "start": 437.36,
        "duration": 4.48
    },
    {
        "text": "and how often these big asteroids to fly",
        "start": 439.72,
        "duration": 4.52
    },
    {
        "text": "by as close to the Earth to see what the",
        "start": 441.84,
        "duration": 5.079
    },
    {
        "text": "probability estimates of U or the P Doom",
        "start": 444.24,
        "duration": 5.28
    },
    {
        "text": "of asteroid impact is we have no such",
        "start": 446.919,
        "duration": 5.241
    },
    {
        "text": "such theories for existential risk um",
        "start": 449.52,
        "duration": 3.959
    },
    {
        "text": "people have tried to come up with",
        "start": 452.16,
        "duration": 3.719
    },
    {
        "text": "theories one theory is that you know",
        "start": 453.479,
        "duration": 5.921
    },
    {
        "text": "once the number of computations um in an",
        "start": 455.879,
        "duration": 5.16
    },
    {
        "text": "AI system equal the number of",
        "start": 459.4,
        "duration": 3.639
    },
    {
        "text": "computations in the human brain that's",
        "start": 461.039,
        "duration": 4.321
    },
    {
        "text": "when we'll have transformative AGI but",
        "start": 463.039,
        "duration": 4.201
    },
    {
        "text": "that tells us nothing about whether this",
        "start": 465.36,
        "duration": 4.32
    },
    {
        "text": "AI is like likely to lead us to sort of",
        "start": 467.24,
        "duration": 4.16
    },
    {
        "text": "the lack of control scenarios that are",
        "start": 469.68,
        "duration": 3.799
    },
    {
        "text": "talked about but more importantly this",
        "start": 471.4,
        "duration": 4.639
    },
    {
        "text": "assumption itself is extremely tenuous",
        "start": 473.479,
        "duration": 5.4
    },
    {
        "text": "we don't understand as well right now",
        "start": 476.039,
        "duration": 5.081
    },
    {
        "text": "whether this is precisely what leads to",
        "start": 478.879,
        "duration": 3.6
    },
    {
        "text": "intelligence whether there are other",
        "start": 481.12,
        "duration": 3.32
    },
    {
        "text": "factors in fact I would say many",
        "start": 482.479,
        "duration": 4.241
    },
    {
        "text": "neuroscientists would vly disagree with",
        "start": 484.44,
        "duration": 4.28
    },
    {
        "text": "the fact that the number of computations",
        "start": 486.72,
        "duration": 4.8
    },
    {
        "text": "is what leads to intelligence um and now",
        "start": 488.72,
        "duration": 4.879
    },
    {
        "text": "this brings us to sort of the final part",
        "start": 491.52,
        "duration": 4.2
    },
    {
        "text": "the part that I set aside for the moment",
        "start": 493.599,
        "duration": 4.921
    },
    {
        "text": "so lacking either inductive theories um",
        "start": 495.72,
        "duration": 4.36
    },
    {
        "text": "so a reference class for making",
        "start": 498.52,
        "duration": 3.84
    },
    {
        "text": "inductive probability estimates or",
        "start": 500.08,
        "duration": 5.32
    },
    {
        "text": "deductive theories about how AI risk",
        "start": 502.36,
        "duration": 5.6
    },
    {
        "text": "might come about what the community has",
        "start": 505.4,
        "duration": 4.56
    },
    {
        "text": "largely turned to when for casting the",
        "start": 507.96,
        "duration": 4.759
    },
    {
        "text": "risk of AI Extinction are subjective",
        "start": 509.96,
        "duration": 4.559
    },
    {
        "text": "probability estimates now what",
        "start": 512.719,
        "duration": 4.44
    },
    {
        "text": "subjective probability estimates do is",
        "start": 514.519,
        "duration": 5.601
    },
    {
        "text": "that they sort of feed into our",
        "start": 517.159,
        "duration": 5.201
    },
    {
        "text": "cognitive biases to take quantification",
        "start": 520.12,
        "duration": 4.44
    },
    {
        "text": "seriously so I think um all of us have",
        "start": 522.36,
        "duration": 4.44
    },
    {
        "text": "many cognitive biases quantification",
        "start": 524.56,
        "duration": 4.959
    },
    {
        "text": "bias is the tendency to take um events",
        "start": 526.8,
        "duration": 4.599
    },
    {
        "text": "that are Quantified more seriously that",
        "start": 529.519,
        "duration": 4.081
    },
    {
        "text": "ones that aren't and so when someone",
        "start": 531.399,
        "duration": 4.601
    },
    {
        "text": "says that the P Doom or the probability",
        "start": 533.6,
        "duration": 5.479
    },
    {
        "text": "of Extinction from AI is 15% we might",
        "start": 536.0,
        "duration": 5.2
    },
    {
        "text": "take it more seriously than we V claims",
        "start": 539.079,
        "duration": 5.041
    },
    {
        "text": "about um I don't know the risk of AI",
        "start": 541.2,
        "duration": 6.52
    },
    {
        "text": "going rogue being High um and I think it",
        "start": 544.12,
        "duration": 5.36
    },
    {
        "text": "if we look at all of the evidence that",
        "start": 547.72,
        "duration": 3.4
    },
    {
        "text": "the community making predictions about",
        "start": 549.48,
        "duration": 4.96
    },
    {
        "text": "Aid Doom have given us um the underlying",
        "start": 551.12,
        "duration": 5.08
    },
    {
        "text": "reasons for these probability estimates",
        "start": 554.44,
        "duration": 4.76
    },
    {
        "text": "are extremely tenur so one of the most",
        "start": 556.2,
        "duration": 4.8
    },
    {
        "text": "important I believe uh prediction",
        "start": 559.2,
        "duration": 4.04
    },
    {
        "text": "tournaments that happened recently was",
        "start": 561.0,
        "duration": 5.24
    },
    {
        "text": "the extinction prediction tournament um",
        "start": 563.24,
        "duration": 5.52
    },
    {
        "text": "it was carried out by Philip tlock and",
        "start": 566.24,
        "duration": 5.039
    },
    {
        "text": "his colleagues and they basically asked",
        "start": 568.76,
        "duration": 5.12
    },
    {
        "text": "um I think 100 or so AI researchers as",
        "start": 571.279,
        "duration": 4.521
    },
    {
        "text": "well as super forecasters that is people",
        "start": 573.88,
        "duration": 4.079
    },
    {
        "text": "who had excellent records at for casting",
        "start": 575.8,
        "duration": 4.88
    },
    {
        "text": "events in the past to participate in a",
        "start": 577.959,
        "duration": 5.241
    },
    {
        "text": "prediction tournament that is to predict",
        "start": 580.68,
        "duration": 5.599
    },
    {
        "text": "um the possibility of x- risk um and it",
        "start": 583.2,
        "duration": 4.879
    },
    {
        "text": "turns out that if you look at the",
        "start": 586.279,
        "duration": 3.641
    },
    {
        "text": "reasons that people gave to justify",
        "start": 588.079,
        "duration": 3.841
    },
    {
        "text": "their abilities those reasons are no",
        "start": 589.92,
        "duration": 3.96
    },
    {
        "text": "better than what we might expect from",
        "start": 591.92,
        "duration": 3.56
    },
    {
        "text": "anyone like on the street who is",
        "start": 593.88,
        "duration": 4.12
    },
    {
        "text": "thinking about AI risk um reasons",
        "start": 595.48,
        "duration": 5.4
    },
    {
        "text": "included things like well maybe AGI",
        "start": 598.0,
        "duration": 4.76
    },
    {
        "text": "would decide to colonize space instead",
        "start": 600.88,
        "duration": 3.959
    },
    {
        "text": "of the earth and so they'll reduce uh",
        "start": 602.76,
        "duration": 4.84
    },
    {
        "text": "their AI Doom risk and and so on um and",
        "start": 604.839,
        "duration": 5.12
    },
    {
        "text": "so what we really take issue with is",
        "start": 607.6,
        "duration": 4.679
    },
    {
        "text": "dressing up these feelings as numbers",
        "start": 609.959,
        "duration": 4.241
    },
    {
        "text": "and making it seem as if there is a",
        "start": 612.279,
        "duration": 4.641
    },
    {
        "text": "precise estimate behind claims that",
        "start": 614.2,
        "duration": 4.24
    },
    {
        "text": "there uh there is a high risk of",
        "start": 616.92,
        "duration": 2.88
    },
    {
        "text": "Extinction from",
        "start": 618.44,
        "duration": 4.6
    },
    {
        "text": "AI so your your article um argues that",
        "start": 619.8,
        "duration": 4.88
    },
    {
        "text": "there are many reasons why these risk",
        "start": 623.04,
        "duration": 3.359
    },
    {
        "text": "estimates might be you know",
        "start": 624.68,
        "duration": 3.88
    },
    {
        "text": "systematically inflated I mean can you",
        "start": 626.399,
        "duration": 3.401
    },
    {
        "text": "can you tell us about some of those",
        "start": 628.56,
        "duration": 3.88
    },
    {
        "text": "reasons absolutely so when we look at",
        "start": 629.8,
        "duration": 4.279
    },
    {
        "text": "the metrics that are used to evaluate",
        "start": 632.44,
        "duration": 4.28
    },
    {
        "text": "these forecasters we find that um they",
        "start": 634.079,
        "duration": 5.921
    },
    {
        "text": "severely overestimate uh the probability",
        "start": 636.72,
        "duration": 5.64
    },
    {
        "text": "that events that might not ever happen",
        "start": 640.0,
        "duration": 4.92
    },
    {
        "text": "or might happen very like infrequently",
        "start": 642.36,
        "duration": 4.479
    },
    {
        "text": "also known as stale risks in a",
        "start": 644.92,
        "duration": 4.479
    },
    {
        "text": "systematic fashion so in the blog post",
        "start": 646.839,
        "duration": 4.961
    },
    {
        "text": "we do an analysis of one such example so",
        "start": 649.399,
        "duration": 4.521
    },
    {
        "text": "let's say we have two forecasters uh",
        "start": 651.8,
        "duration": 4.24
    },
    {
        "text": "forecaster 1 and forecaster 2 um",
        "start": 653.92,
        "duration": 4.44
    },
    {
        "text": "forecaster 1 always makes the correct",
        "start": 656.04,
        "duration": 3.88
    },
    {
        "text": "probability estimate based on their",
        "start": 658.36,
        "duration": 4.159
    },
    {
        "text": "prior forecaster 2 makes the exact same",
        "start": 659.92,
        "duration": 5.52
    },
    {
        "text": "estimate except if the risk is less than",
        "start": 662.519,
        "duration": 6.241
    },
    {
        "text": "1% they always predict the risk to be 1%",
        "start": 665.44,
        "duration": 5.36
    },
    {
        "text": "so in some sense forecaster 2 is",
        "start": 668.76,
        "duration": 3.879
    },
    {
        "text": "overestimating tail risks that is",
        "start": 670.8,
        "duration": 3.96
    },
    {
        "text": "they're overestimating all risks that",
        "start": 672.639,
        "duration": 3.961
    },
    {
        "text": "have a less than 1% probability of",
        "start": 674.76,
        "duration": 4.44
    },
    {
        "text": "occurring now if we assume that the",
        "start": 676.6,
        "duration": 5.76
    },
    {
        "text": "probability distribution is uniform um",
        "start": 679.2,
        "duration": 4.879
    },
    {
        "text": "and we want to find out which of these",
        "start": 682.36,
        "duration": 4.52
    },
    {
        "text": "two forecasters is better um can you",
        "start": 684.079,
        "duration": 5.0
    },
    {
        "text": "take a guess as to how many forecasts it",
        "start": 686.88,
        "duration": 4.16
    },
    {
        "text": "would take for us to get an estimate of",
        "start": 689.079,
        "duration": 3.281
    },
    {
        "text": "whether forecaster 1 is better than",
        "start": 691.04,
        "duration": 4.599
    },
    {
        "text": "forecaster 2 it turns out to be in the",
        "start": 692.36,
        "duration": 5.599
    },
    {
        "text": "hundreds of millions and that is for the",
        "start": 695.639,
        "duration": 4.281
    },
    {
        "text": "simple scoring rules the scoring rules",
        "start": 697.959,
        "duration": 4.841
    },
    {
        "text": "that are not so sensitive to TA",
        "start": 699.92,
        "duration": 4.919
    },
    {
        "text": "overestimating tail risks if you look at",
        "start": 702.8,
        "duration": 4.24
    },
    {
        "text": "scores like the Brier rule for example",
        "start": 704.839,
        "duration": 4.841
    },
    {
        "text": "the estimate is closer to a trillion so",
        "start": 707.04,
        "duration": 4.16
    },
    {
        "text": "in other words it would take us a",
        "start": 709.68,
        "duration": 4.24
    },
    {
        "text": "trillion observations to be able to tell",
        "start": 711.2,
        "duration": 5.04
    },
    {
        "text": "if forecaster one who is predicting",
        "start": 713.92,
        "duration": 5.52
    },
    {
        "text": "let's say a probability of 0.001",
        "start": 716.24,
        "duration": 5.08
    },
    {
        "text": "is better at forecasting than forecaster",
        "start": 719.44,
        "duration": 5.0
    },
    {
        "text": "2 who just says a probability of 1% to",
        "start": 721.32,
        "duration": 4.959
    },
    {
        "text": "tail risks you you mentioned the the",
        "start": 724.44,
        "duration": 4.079
    },
    {
        "text": "dangers of utility maximization when it",
        "start": 726.279,
        "duration": 4.601
    },
    {
        "text": "comes to x- risks how should policy",
        "start": 728.519,
        "duration": 4.241
    },
    {
        "text": "makers approach this problem uh without",
        "start": 730.88,
        "duration": 3.639
    },
    {
        "text": "falling trapped to Pascal's wager and if",
        "start": 732.76,
        "duration": 3.0
    },
    {
        "text": "you wouldn't mind could you explain what",
        "start": 734.519,
        "duration": 4.12
    },
    {
        "text": "Pascal's wager is absolutely so Pascal's",
        "start": 735.76,
        "duration": 4.759
    },
    {
        "text": "wager is this very interesting thought",
        "start": 738.639,
        "duration": 3.921
    },
    {
        "text": "experiment about whether one should",
        "start": 740.519,
        "duration": 4.88
    },
    {
        "text": "believe in God um so it states that one",
        "start": 742.56,
        "duration": 5.24
    },
    {
        "text": "should always believe in God because if",
        "start": 745.399,
        "duration": 5.041
    },
    {
        "text": "it turns out that God does indeed exist",
        "start": 747.8,
        "duration": 4.88
    },
    {
        "text": "and one does not believe in God there's",
        "start": 750.44,
        "duration": 4.839
    },
    {
        "text": "an essentially infinitely negative",
        "start": 752.68,
        "duration": 5.279
    },
    {
        "text": "utility function to that uh to that call",
        "start": 755.279,
        "duration": 4.881
    },
    {
        "text": "because it's like an infinite Life In",
        "start": 757.959,
        "duration": 4.56
    },
    {
        "text": "Hell whereas so if there's even a small",
        "start": 760.16,
        "duration": 4.119
    },
    {
        "text": "possibility that God exists one should",
        "start": 762.519,
        "duration": 4.081
    },
    {
        "text": "always believe in God um so this is an",
        "start": 764.279,
        "duration": 5.24
    },
    {
        "text": "example of the dangers of utilitarianism",
        "start": 766.6,
        "duration": 5.12
    },
    {
        "text": "in dealing with uh making consequential",
        "start": 769.519,
        "duration": 4.961
    },
    {
        "text": "decisions um because let's say let's",
        "start": 771.72,
        "duration": 5.4
    },
    {
        "text": "take the example of X risk um what if we",
        "start": 774.48,
        "duration": 5.44
    },
    {
        "text": "try to estimate the utility the expected",
        "start": 777.12,
        "duration": 6.04
    },
    {
        "text": "utility of uh existential risk even if",
        "start": 779.92,
        "duration": 5.84
    },
    {
        "text": "we have a very low probability now some",
        "start": 783.16,
        "duration": 4.44
    },
    {
        "text": "of us and like reasonable people might",
        "start": 785.76,
        "duration": 4.68
    },
    {
        "text": "conclude that the cost of humanity going",
        "start": 787.6,
        "duration": 5.599
    },
    {
        "text": "extinct is essentially infinite there's",
        "start": 790.44,
        "duration": 4.8
    },
    {
        "text": "probably nothing worse that could happen",
        "start": 793.199,
        "duration": 4.041
    },
    {
        "text": "and therefore if you have even a very",
        "start": 795.24,
        "duration": 4.92
    },
    {
        "text": "small probability that is nonzero that",
        "start": 797.24,
        "duration": 4.599
    },
    {
        "text": "Humanity goes extinct you're",
        "start": 800.16,
        "duration": 4.239
    },
    {
        "text": "incentivized to always do in everything",
        "start": 801.839,
        "duration": 5.201
    },
    {
        "text": "in your power to stop existential risk",
        "start": 804.399,
        "duration": 4.201
    },
    {
        "text": "so if you were to take this seriously if",
        "start": 807.04,
        "duration": 4.44
    },
    {
        "text": "you were to adopt a purely utilitarian",
        "start": 808.6,
        "duration": 6.4
    },
    {
        "text": "um expectation maximization um Theory um",
        "start": 811.48,
        "duration": 5.96
    },
    {
        "text": "and apply it to real world decisions all",
        "start": 815.0,
        "duration": 5.32
    },
    {
        "text": "policy makers would ever do at any given",
        "start": 817.44,
        "duration": 6.12
    },
    {
        "text": "point of time is talk about xrk by the",
        "start": 820.32,
        "duration": 5.319
    },
    {
        "text": "way your blog is amazing um these guys",
        "start": 823.56,
        "duration": 3.76
    },
    {
        "text": "have have got theum the snake oil blog",
        "start": 825.639,
        "duration": 4.32
    },
    {
        "text": "on substack and it's it's probably my my",
        "start": 827.32,
        "duration": 4.4
    },
    {
        "text": "favorite blog that I that I read on",
        "start": 829.959,
        "duration": 3.521
    },
    {
        "text": "substack and so I was reading back a",
        "start": 831.72,
        "duration": 3.479
    },
    {
        "text": "little bit but you had one about AI",
        "start": 833.48,
        "duration": 4.08
    },
    {
        "text": "scaling myths and let's start with you",
        "start": 835.199,
        "duration": 4.2
    },
    {
        "text": "know how do scaling laws compare to",
        "start": 837.56,
        "duration": 4.199
    },
    {
        "text": "other scaling plateaus you know like air",
        "start": 839.399,
        "duration": 4.641
    },
    {
        "text": "airplane speeds for example um so",
        "start": 841.759,
        "duration": 4.681
    },
    {
        "text": "there's a strong tendency in like the",
        "start": 844.04,
        "duration": 4.479
    },
    {
        "text": "field of AI in some parts of the field",
        "start": 846.44,
        "duration": 4.6
    },
    {
        "text": "of AI but more broadly in the field of",
        "start": 848.519,
        "duration": 5.44
    },
    {
        "text": "people talking about AI to assume that",
        "start": 851.04,
        "duration": 5.0
    },
    {
        "text": "um exponential Trends can hold",
        "start": 853.959,
        "duration": 4.641
    },
    {
        "text": "indefinitely um I think very recently I",
        "start": 856.04,
        "duration": 4.359
    },
    {
        "text": "read this piece called situational",
        "start": 858.6,
        "duration": 4.28
    },
    {
        "text": "awareness that draws these trend lines",
        "start": 860.399,
        "duration": 4.961
    },
    {
        "text": "that go all the way up to the right um",
        "start": 862.88,
        "duration": 4.639
    },
    {
        "text": "and argues on this basis that we'll get",
        "start": 865.36,
        "duration": 4.399
    },
    {
        "text": "to AGI sometime very soon",
        "start": 867.519,
        "duration": 4.0
    },
    {
        "text": "now our piece on a scaling mits was not",
        "start": 869.759,
        "duration": 3.361
    },
    {
        "text": "a direct response to the situational",
        "start": 871.519,
        "duration": 3.041
    },
    {
        "text": "awareness piece a lot of people thought",
        "start": 873.12,
        "duration": 3.399
    },
    {
        "text": "it was but we'd actually been working on",
        "start": 874.56,
        "duration": 4.6
    },
    {
        "text": "it for for a little bit of time um but",
        "start": 876.519,
        "duration": 4.281
    },
    {
        "text": "essentially if we look back at the",
        "start": 879.16,
        "duration": 3.72
    },
    {
        "text": "history of what happens to things that",
        "start": 880.8,
        "duration": 4.44
    },
    {
        "text": "people have thought are exponentials",
        "start": 882.88,
        "duration": 4.319
    },
    {
        "text": "what happens when we sort of look past",
        "start": 885.24,
        "duration": 3.68
    },
    {
        "text": "let's say the first few years of this",
        "start": 887.199,
        "duration": 4.481
    },
    {
        "text": "type of exponential we found that uh",
        "start": 888.92,
        "duration": 4.4
    },
    {
        "text": "people have largely been disappointed I",
        "start": 891.68,
        "duration": 3.64
    },
    {
        "text": "think there's a saying that goes every",
        "start": 893.32,
        "duration": 3.84
    },
    {
        "text": "exponential is a sigmoid looking",
        "start": 895.32,
        "duration": 4.0
    },
    {
        "text": "backwards um and so this is exactly what",
        "start": 897.16,
        "duration": 4.32
    },
    {
        "text": "happened with airplane speeds um I think",
        "start": 899.32,
        "duration": 5.28
    },
    {
        "text": "in the early 1970s or late 1960s people",
        "start": 901.48,
        "duration": 5.56
    },
    {
        "text": "were booking flights to the Moon based",
        "start": 904.6,
        "duration": 4.359
    },
    {
        "text": "on the increasing trend of airplane",
        "start": 907.04,
        "duration": 4.159
    },
    {
        "text": "speeds at the time and then essentially",
        "start": 908.959,
        "duration": 4.0
    },
    {
        "text": "all of a sudden these increasing",
        "start": 911.199,
        "duration": 4.32
    },
    {
        "text": "airplane speeds came to a halt um we had",
        "start": 912.959,
        "duration": 4.841
    },
    {
        "text": "the saturated around the speeds that we",
        "start": 915.519,
        "duration": 4.401
    },
    {
        "text": "have today um and the reasons for that",
        "start": 917.8,
        "duration": 4.08
    },
    {
        "text": "were a little bit technical a little bit",
        "start": 919.92,
        "duration": 3.76
    },
    {
        "text": "business related but essentially it",
        "start": 921.88,
        "duration": 3.759
    },
    {
        "text": "shows the Perils of uh thinking that",
        "start": 923.68,
        "duration": 4.12
    },
    {
        "text": "trend lines can continue forever um I",
        "start": 925.639,
        "duration": 4.081
    },
    {
        "text": "think there are always bottl that arise",
        "start": 927.8,
        "duration": 3.68
    },
    {
        "text": "when a previous bottlenecks uh when",
        "start": 929.72,
        "duration": 3.919
    },
    {
        "text": "previous bottlenecks are fixed and",
        "start": 931.48,
        "duration": 4.44
    },
    {
        "text": "that's how we've also seen progress in",
        "start": 933.639,
        "duration": 5.0
    },
    {
        "text": "AI if we go back um I don't know 50",
        "start": 935.92,
        "duration": 5.359
    },
    {
        "text": "years um in the last 50 years we see",
        "start": 938.639,
        "duration": 5.081
    },
    {
        "text": "that AI progress has been a punctuated",
        "start": 941.279,
        "duration": 4.92
    },
    {
        "text": "equilibrium so every time we have a new",
        "start": 943.72,
        "duration": 4.88
    },
    {
        "text": "paradigm there's a lot of uh like",
        "start": 946.199,
        "duration": 5.32
    },
    {
        "text": "resources a lot of um intellectual as",
        "start": 948.6,
        "duration": 4.2
    },
    {
        "text": "well as material resources that are",
        "start": 951.519,
        "duration": 4.68
    },
    {
        "text": "spent in improving this Paradigm um and",
        "start": 952.8,
        "duration": 5.24
    },
    {
        "text": "this is how progress takes place until",
        "start": 956.199,
        "duration": 4.241
    },
    {
        "text": "we've saturated a Paradigm uh and once",
        "start": 958.04,
        "duration": 3.76
    },
    {
        "text": "we saturate a paradigm there is",
        "start": 960.44,
        "duration": 2.68
    },
    {
        "text": "essentially a period where we're looking",
        "start": 961.8,
        "duration": 3.44
    },
    {
        "text": "for the next Paradigm and progress sort",
        "start": 963.12,
        "duration": 4.24
    },
    {
        "text": "of slows down it becomes the sigmoid not",
        "start": 965.24,
        "duration": 4.039
    },
    {
        "text": "the exponential anymore just a quick",
        "start": 967.36,
        "duration": 3.64
    },
    {
        "text": "digression on that situational awareness",
        "start": 969.279,
        "duration": 3.721
    },
    {
        "text": "piece I mean uh as you can guess I'm I'm",
        "start": 971.0,
        "duration": 3.56
    },
    {
        "text": "not a big fan of it and to me it",
        "start": 973.0,
        "duration": 3.519
    },
    {
        "text": "represents the worst of Silicon Valley",
        "start": 974.56,
        "duration": 3.48
    },
    {
        "text": "group thing but do you have any uh",
        "start": 976.519,
        "duration": 4.921
    },
    {
        "text": "comments on that I mean to be clear I",
        "start": 978.04,
        "duration": 5.64
    },
    {
        "text": "don't think uh that like the piece is",
        "start": 981.44,
        "duration": 4.319
    },
    {
        "text": "awful I think it makes for entertaining",
        "start": 983.68,
        "duration": 4.12
    },
    {
        "text": "speculation but I think it could be",
        "start": 985.759,
        "duration": 4.241
    },
    {
        "text": "harmful if we don't treat it as such so",
        "start": 987.8,
        "duration": 3.959
    },
    {
        "text": "I think if we look at sort of these",
        "start": 990.0,
        "duration": 3.56
    },
    {
        "text": "predictions about the future more as",
        "start": 991.759,
        "duration": 3.76
    },
    {
        "text": "science fiction and less as what's",
        "start": 993.56,
        "duration": 4.16
    },
    {
        "text": "actually going to take place um I think",
        "start": 995.519,
        "duration": 3.56
    },
    {
        "text": "they're perfectly harmless so the pece",
        "start": 997.72,
        "duration": 2.96
    },
    {
        "text": "in and of itself seems completely",
        "start": 999.079,
        "duration": 4.041
    },
    {
        "text": "harmless to me what then becomes harmful",
        "start": 1000.68,
        "duration": 4.639
    },
    {
        "text": "is we sees taking this seriously as a",
        "start": 1003.12,
        "duration": 4.44
    },
    {
        "text": "means to allocate funding as a means of",
        "start": 1005.319,
        "duration": 4.361
    },
    {
        "text": "prioritizing what products actually get",
        "start": 1007.56,
        "duration": 4.6
    },
    {
        "text": "built in the real world um and I think",
        "start": 1009.68,
        "duration": 4.159
    },
    {
        "text": "that that's where the group thing comes",
        "start": 1012.16,
        "duration": 4.0
    },
    {
        "text": "in and I do think like this is a strong",
        "start": 1013.839,
        "duration": 4.36
    },
    {
        "text": "tendency because I was reading a report",
        "start": 1016.16,
        "duration": 4.159
    },
    {
        "text": "that said half of VC money in the last",
        "start": 1018.199,
        "duration": 4.64
    },
    {
        "text": "year was spent on generative AI um and",
        "start": 1020.319,
        "duration": 4.961
    },
    {
        "text": "at some point I think as a community",
        "start": 1022.839,
        "duration": 4.441
    },
    {
        "text": "VC's have to think about whether that's",
        "start": 1025.28,
        "duration": 3.72
    },
    {
        "text": "really the best allocation of their own",
        "start": 1027.28,
        "duration": 4.32
    },
    {
        "text": "money but that also of uh like the best",
        "start": 1029.0,
        "duration": 4.28
    },
    {
        "text": "way to Spur up Innovation because any",
        "start": 1031.6,
        "duration": 3.88
    },
    {
        "text": "singular VC of course wants to maximize",
        "start": 1033.28,
        "duration": 3.919
    },
    {
        "text": "the Returns on their investment but as a",
        "start": 1035.48,
        "duration": 3.92
    },
    {
        "text": "community there's also the question of",
        "start": 1037.199,
        "duration": 3.921
    },
    {
        "text": "uh spurring Innovation on an ecosystem",
        "start": 1039.4,
        "duration": 3.76
    },
    {
        "text": "level yeah I I agree with your take I",
        "start": 1041.12,
        "duration": 4.04
    },
    {
        "text": "mean I'm in the UK and certainly in the",
        "start": 1043.16,
        "duration": 3.6
    },
    {
        "text": "outgoing government the policy makers",
        "start": 1045.16,
        "duration": 3.24
    },
    {
        "text": "were taking that kind of thing very",
        "start": 1046.76,
        "duration": 3.64
    },
    {
        "text": "seriously so that this this is very very",
        "start": 1048.4,
        "duration": 4.2
    },
    {
        "text": "important but shifting a little bit you",
        "start": 1050.4,
        "duration": 3.32
    },
    {
        "text": "know do you think we're going to see a",
        "start": 1052.6,
        "duration": 3.92
    },
    {
        "text": "shift to smaller more efficient models",
        "start": 1053.72,
        "duration": 4.8
    },
    {
        "text": "oh absolutely I'm a big fan of",
        "start": 1056.52,
        "duration": 4.56
    },
    {
        "text": "efficiency um I think one of the best",
        "start": 1058.52,
        "duration": 5.44
    },
    {
        "text": "ways to make actual real progress in the",
        "start": 1061.08,
        "duration": 5.36
    },
    {
        "text": "real world today is um through models",
        "start": 1063.96,
        "duration": 4.48
    },
    {
        "text": "that we can run multiple times let's say",
        "start": 1066.44,
        "duration": 4.08
    },
    {
        "text": "for the same task models that are within",
        "start": 1068.44,
        "duration": 4.599
    },
    {
        "text": "reach for smaller developers um for",
        "start": 1070.52,
        "duration": 4.36
    },
    {
        "text": "tasks that might not require the best",
        "start": 1073.039,
        "duration": 3.361
    },
    {
        "text": "model actually tasks that can be",
        "start": 1074.88,
        "duration": 3.72
    },
    {
        "text": "accomplished by smaller ones um and in",
        "start": 1076.4,
        "duration": 3.759
    },
    {
        "text": "some sense I think we're already seeing",
        "start": 1078.6,
        "duration": 4.0
    },
    {
        "text": "this trend um we've seen that the",
        "start": 1080.159,
        "duration": 5.0
    },
    {
        "text": "frontier models for literally every",
        "start": 1082.6,
        "duration": 5.92
    },
    {
        "text": "single um AI company today are not their",
        "start": 1085.159,
        "duration": 6.801
    },
    {
        "text": "most expensive models so GPT 40 is less",
        "start": 1088.52,
        "duration": 6.72
    },
    {
        "text": "expensive than gp4 turbo and gp4 um",
        "start": 1091.96,
        "duration": 6.04
    },
    {
        "text": "Germany 1.5 Pro is less expensive than",
        "start": 1095.24,
        "duration": 5.439
    },
    {
        "text": "Germany 1.0 Ultra claw 3.5 Sonet is less",
        "start": 1098.0,
        "duration": 4.679
    },
    {
        "text": "expensive than CLA 3 oppus and so in",
        "start": 1100.679,
        "duration": 3.681
    },
    {
        "text": "some sense it seems like companies have",
        "start": 1102.679,
        "duration": 3.841
    },
    {
        "text": "also started to see the value in",
        "start": 1104.36,
        "duration": 4.199
    },
    {
        "text": "reducing the cost um and making things",
        "start": 1106.52,
        "duration": 5.039
    },
    {
        "text": "more accessible and like another step on",
        "start": 1108.559,
        "duration": 5.36
    },
    {
        "text": "that trend is the is that companies are",
        "start": 1111.559,
        "duration": 4.321
    },
    {
        "text": "releasing even smaller versions of their",
        "start": 1113.919,
        "duration": 3.601
    },
    {
        "text": "Frontier models which I think is",
        "start": 1115.88,
        "duration": 3.88
    },
    {
        "text": "extremely promising so I mean writing",
        "start": 1117.52,
        "duration": 3.88
    },
    {
        "text": "the blog is only like a small part of",
        "start": 1119.76,
        "duration": 3.48
    },
    {
        "text": "the work I do I also do like a lot of",
        "start": 1121.4,
        "duration": 4.519
    },
    {
        "text": "Air Research and having access to",
        "start": 1123.24,
        "duration": 4.2
    },
    {
        "text": "cheaper models that we can use for",
        "start": 1125.919,
        "duration": 3.681
    },
    {
        "text": "solving real world research problems is",
        "start": 1127.44,
        "duration": 4.04
    },
    {
        "text": "something that has greatly improved the",
        "start": 1129.6,
        "duration": 4.24
    },
    {
        "text": "accessibility um of This research in my",
        "start": 1131.48,
        "duration": 4.6
    },
    {
        "text": "own work as well so we're developing",
        "start": 1133.84,
        "duration": 3.88
    },
    {
        "text": "agents we're developing benchmarks all",
        "start": 1136.08,
        "duration": 3.76
    },
    {
        "text": "of this is aided by the fact that you",
        "start": 1137.72,
        "duration": 4.48
    },
    {
        "text": "know GPD 40 costs like a tenth of the",
        "start": 1139.84,
        "duration": 5.959
    },
    {
        "text": "cost of um GPD 4 um yes and I'm I'm",
        "start": 1142.2,
        "duration": 5.08
    },
    {
        "text": "really interested in your AG paper and",
        "start": 1145.799,
        "duration": 3.161
    },
    {
        "text": "we'll get to that um shortly but just",
        "start": 1147.28,
        "duration": 2.68
    },
    {
        "text": "before we move on though a good",
        "start": 1148.96,
        "duration": 2.36
    },
    {
        "text": "digression here is you know what do you",
        "start": 1149.96,
        "duration": 3.12
    },
    {
        "text": "think of the commercial llm ecosystem",
        "start": 1151.32,
        "duration": 3.16
    },
    {
        "text": "you know what what are the Dynamics",
        "start": 1153.08,
        "duration": 3.8
    },
    {
        "text": "there um I think that's a great question",
        "start": 1154.48,
        "duration": 4.0
    },
    {
        "text": "and it's an interesting time to think",
        "start": 1156.88,
        "duration": 3.24
    },
    {
        "text": "about this question as well because for",
        "start": 1158.48,
        "duration": 3.72
    },
    {
        "text": "a period of time between 2023 and",
        "start": 1160.12,
        "duration": 5.6
    },
    {
        "text": "earlier this year um GPD 4 was",
        "start": 1162.2,
        "duration": 6.16
    },
    {
        "text": "undoubtedly the leader in the space um",
        "start": 1165.72,
        "duration": 4.28
    },
    {
        "text": "there were questions around whether open",
        "start": 1168.36,
        "duration": 4.24
    },
    {
        "text": "AI had something special um open a had",
        "start": 1170.0,
        "duration": 4.12
    },
    {
        "text": "been had done something that no one else",
        "start": 1172.6,
        "duration": 3.24
    },
    {
        "text": "had been able to reproduce there were",
        "start": 1174.12,
        "duration": 4.32
    },
    {
        "text": "questions around um you know gp4 itself",
        "start": 1175.84,
        "duration": 5.64
    },
    {
        "text": "being special so you know gp4 in some",
        "start": 1178.44,
        "duration": 4.479
    },
    {
        "text": "cases in the communities that we were",
        "start": 1181.48,
        "duration": 3.439
    },
    {
        "text": "just talking about was seen as the model",
        "start": 1182.919,
        "duration": 3.841
    },
    {
        "text": "that is helping open a do a lot better",
        "start": 1184.919,
        "duration": 3.12
    },
    {
        "text": "and they're integrating it in their own",
        "start": 1186.76,
        "duration": 4.159
    },
    {
        "text": "workflows and so on uh I think we can",
        "start": 1188.039,
        "duration": 4.921
    },
    {
        "text": "fairly say that today I think it is a",
        "start": 1190.919,
        "duration": 3.961
    },
    {
        "text": "repeatable process it's the outcome of",
        "start": 1192.96,
        "duration": 3.719
    },
    {
        "text": "good engineering and good data and so as",
        "start": 1194.88,
        "duration": 4.279
    },
    {
        "text": "a result like GPD 4 is not really",
        "start": 1196.679,
        "duration": 5.36
    },
    {
        "text": "special anymore uh we have models from",
        "start": 1199.159,
        "duration": 5.121
    },
    {
        "text": "at least three companies that are as",
        "start": 1202.039,
        "duration": 4.921
    },
    {
        "text": "good as or better than gbd4 uh in most",
        "start": 1204.28,
        "duration": 5.96
    },
    {
        "text": "tasks um including encoding reasoning um",
        "start": 1206.96,
        "duration": 5.56
    },
    {
        "text": "writing abilities and so on and so that",
        "start": 1210.24,
        "duration": 4.799
    },
    {
        "text": "puts us in a very special place because",
        "start": 1212.52,
        "duration": 4.8
    },
    {
        "text": "we have seen these companies and the",
        "start": 1215.039,
        "duration": 4.0
    },
    {
        "text": "companies themselves have seen",
        "start": 1217.32,
        "duration": 4.92
    },
    {
        "text": "themselves um as building Gods to some",
        "start": 1219.039,
        "duration": 5.241
    },
    {
        "text": "extent the promise is that we'll bring",
        "start": 1222.24,
        "duration": 4.64
    },
    {
        "text": "safe and beneficial AGI into this world",
        "start": 1224.28,
        "duration": 4.08
    },
    {
        "text": "but increasingly it seems like these",
        "start": 1226.88,
        "duration": 3.4
    },
    {
        "text": "compan are building products these are",
        "start": 1228.36,
        "duration": 3.96
    },
    {
        "text": "products that can be commoditized um",
        "start": 1230.28,
        "duration": 5.24
    },
    {
        "text": "meta actually has uh explicitly and",
        "start": 1232.32,
        "duration": 4.839
    },
    {
        "text": "openly said that they want to",
        "start": 1235.52,
        "duration": 3.36
    },
    {
        "text": "commoditize their complement um and",
        "start": 1237.159,
        "duration": 2.76
    },
    {
        "text": "that's why they're releasing these",
        "start": 1238.88,
        "duration": 3.799
    },
    {
        "text": "models openly um and so when we have",
        "start": 1239.919,
        "duration": 5.201
    },
    {
        "text": "open models that are widely available to",
        "start": 1242.679,
        "duration": 4.201
    },
    {
        "text": "the general public that are as capable",
        "start": 1245.12,
        "duration": 4.08
    },
    {
        "text": "as gp4 um I think a lot of the",
        "start": 1246.88,
        "duration": 4.2
    },
    {
        "text": "mythmaking around large language model",
        "start": 1249.2,
        "duration": 4.959
    },
    {
        "text": "goes away um and essentially the way in",
        "start": 1251.08,
        "duration": 4.479
    },
    {
        "text": "which we should look at them is much",
        "start": 1254.159,
        "duration": 3.721
    },
    {
        "text": "more as consumer products competing in",
        "start": 1255.559,
        "duration": 5.48
    },
    {
        "text": "an open market as opposed to um products",
        "start": 1257.88,
        "duration": 5.08
    },
    {
        "text": "or like companies that are going to get",
        "start": 1261.039,
        "duration": 3.841
    },
    {
        "text": "us to safe and beneficial AGI whatever",
        "start": 1262.96,
        "duration": 4.12
    },
    {
        "text": "AGI means yeah I mean I I agree that the",
        "start": 1264.88,
        "duration": 4.56
    },
    {
        "text": "AGI delusion is is fading away and I",
        "start": 1267.08,
        "duration": 4.199
    },
    {
        "text": "agree with the shift of products I think",
        "start": 1269.44,
        "duration": 4.04
    },
    {
        "text": "part of the thing is originally",
        "start": 1271.279,
        "duration": 4.201
    },
    {
        "text": "companies thought that llms were their",
        "start": 1273.48,
        "duration": 3.6
    },
    {
        "text": "meal ticket and that's all they needed",
        "start": 1275.48,
        "duration": 4.439
    },
    {
        "text": "to sell and they're not as general as we",
        "start": 1277.08,
        "duration": 4.76
    },
    {
        "text": "thought they were and also when you do",
        "start": 1279.919,
        "duration": 3.801
    },
    {
        "text": "software engineering reliability",
        "start": 1281.84,
        "duration": 3.88
    },
    {
        "text": "engineering is an ongoing concern right",
        "start": 1283.72,
        "duration": 3.439
    },
    {
        "text": "you have you know your fine tuning",
        "start": 1285.72,
        "duration": 2.88
    },
    {
        "text": "models you're adding data in your",
        "start": 1287.159,
        "duration": 2.441
    },
    {
        "text": "testing when you put them into",
        "start": 1288.6,
        "duration": 2.559
    },
    {
        "text": "production they they suddenly surprise",
        "start": 1289.6,
        "duration": 2.959
    },
    {
        "text": "you and do things you don't want to you",
        "start": 1291.159,
        "duration": 4.0
    },
    {
        "text": "know even if you're building rag systems",
        "start": 1292.559,
        "duration": 4.161
    },
    {
        "text": "information retrieval you know in the",
        "start": 1295.159,
        "duration": 3.801
    },
    {
        "text": "Enterprise was already a costly Endeavor",
        "start": 1296.72,
        "duration": 3.68
    },
    {
        "text": "you've got security problems and all",
        "start": 1298.96,
        "duration": 3.28
    },
    {
        "text": "sorts of stuff and you can't just rub",
        "start": 1300.4,
        "duration": 4.519
    },
    {
        "text": "magic llms into it it's a very difficult",
        "start": 1302.24,
        "duration": 4.679
    },
    {
        "text": "thing and they're not really helping",
        "start": 1304.919,
        "duration": 4.601
    },
    {
        "text": "Enterprise solve those problems yeah",
        "start": 1306.919,
        "duration": 5.721
    },
    {
        "text": "absolutely I mean uh I think with the in",
        "start": 1309.52,
        "duration": 5.519
    },
    {
        "text": "with the introduction of search GPT uh I",
        "start": 1312.64,
        "duration": 3.96
    },
    {
        "text": "think open air was also made keenly",
        "start": 1315.039,
        "duration": 3.76
    },
    {
        "text": "aware of the problem so I think we've",
        "start": 1316.6,
        "duration": 3.959
    },
    {
        "text": "essentially had no companies that have",
        "start": 1318.799,
        "duration": 4.401
    },
    {
        "text": "used llms to create search products that",
        "start": 1320.559,
        "duration": 5.12
    },
    {
        "text": "have in their demo videos uh not had",
        "start": 1323.2,
        "duration": 4.8
    },
    {
        "text": "hallucinations sort of ruin the ruin the",
        "start": 1325.679,
        "duration": 4.921
    },
    {
        "text": "show for them yes yes indeed what do you",
        "start": 1328.0,
        "duration": 5.52
    },
    {
        "text": "think is the role of synthetic data um I",
        "start": 1330.6,
        "duration": 4.679
    },
    {
        "text": "think synthetic data is important in so",
        "start": 1333.52,
        "duration": 4.36
    },
    {
        "text": "far as it can be used for specific",
        "start": 1335.279,
        "duration": 4.76
    },
    {
        "text": "capabilities for improving the data",
        "start": 1337.88,
        "duration": 4.24
    },
    {
        "text": "generating pipelines for rephrasing",
        "start": 1340.039,
        "duration": 3.801
    },
    {
        "text": "things in ways that make the llms",
        "start": 1342.12,
        "duration": 3.96
    },
    {
        "text": "perform better uh but in general",
        "start": 1343.84,
        "duration": 3.92
    },
    {
        "text": "synthetic data has made out has been",
        "start": 1346.08,
        "duration": 3.479
    },
    {
        "text": "made out to be far far more than at",
        "start": 1347.76,
        "duration": 3.96
    },
    {
        "text": "least I think it is um so I think",
        "start": 1349.559,
        "duration": 3.761
    },
    {
        "text": "there's been speculation that synthetic",
        "start": 1351.72,
        "duration": 4.24
    },
    {
        "text": "data will be the only thing we need uh",
        "start": 1353.32,
        "duration": 5.56
    },
    {
        "text": "in a very short period of time um and",
        "start": 1355.96,
        "duration": 5.719
    },
    {
        "text": "you know this this speculation arises",
        "start": 1358.88,
        "duration": 5.32
    },
    {
        "text": "from a place of reasonableness um",
        "start": 1361.679,
        "duration": 4.401
    },
    {
        "text": "everyone is recognizing that AI",
        "start": 1364.2,
        "duration": 3.8
    },
    {
        "text": "companies are running out of training",
        "start": 1366.08,
        "duration": 4.92
    },
    {
        "text": "data um that um the open web is",
        "start": 1368.0,
        "duration": 5.0
    },
    {
        "text": "increasingly not open not as open",
        "start": 1371.0,
        "duration": 5.159
    },
    {
        "text": "anymore to AI products and AI crawlers",
        "start": 1373.0,
        "duration": 6.039
    },
    {
        "text": "um and so what do companies do um and I",
        "start": 1376.159,
        "duration": 4.76
    },
    {
        "text": "think the speculation has been that AI",
        "start": 1379.039,
        "duration": 3.321
    },
    {
        "text": "companies will not turn to synthetic",
        "start": 1380.919,
        "duration": 2.88
    },
    {
        "text": "data which will lead to the",
        "start": 1382.36,
        "duration": 4.16
    },
    {
        "text": "self-improving cycle um this is very",
        "start": 1383.799,
        "duration": 4.48
    },
    {
        "text": "interesting because we've also at the",
        "start": 1386.52,
        "duration": 4.039
    },
    {
        "text": "same time uh seen issues with model",
        "start": 1388.279,
        "duration": 4.161
    },
    {
        "text": "collapse I think just yesterday nature",
        "start": 1390.559,
        "duration": 3.921
    },
    {
        "text": "released its somewhat controversial",
        "start": 1392.44,
        "duration": 4.119
    },
    {
        "text": "paper on model collapse uh which",
        "start": 1394.48,
        "duration": 3.72
    },
    {
        "text": "basically says that as you start",
        "start": 1396.559,
        "duration": 4.6
    },
    {
        "text": "training models on their own outputs um",
        "start": 1398.2,
        "duration": 4.76
    },
    {
        "text": "the models quality substantially",
        "start": 1401.159,
        "duration": 3.64
    },
    {
        "text": "degrades um I think the truth is",
        "start": 1402.96,
        "duration": 4.52
    },
    {
        "text": "somewhere in between so you know we can",
        "start": 1404.799,
        "duration": 5.081
    },
    {
        "text": "use synthetic data for some domain",
        "start": 1407.48,
        "duration": 4.64
    },
    {
        "text": "specific improvements we have seen time",
        "start": 1409.88,
        "duration": 4.88
    },
    {
        "text": "and time again we can use it for um",
        "start": 1412.12,
        "duration": 4.36
    },
    {
        "text": "alignment tasks we can use it for",
        "start": 1414.76,
        "duration": 3.84
    },
    {
        "text": "eliciting preferences but at the same",
        "start": 1416.48,
        "duration": 4.72
    },
    {
        "text": "time like I think model collapse thinks",
        "start": 1418.6,
        "duration": 5.0
    },
    {
        "text": "about or or looks at this as if we're",
        "start": 1421.2,
        "duration": 4.32
    },
    {
        "text": "not having any human intervention or",
        "start": 1423.6,
        "duration": 4.079
    },
    {
        "text": "filtering that's going on in between um",
        "start": 1425.52,
        "duration": 3.44
    },
    {
        "text": "and that's not really true right like",
        "start": 1427.679,
        "duration": 2.641
    },
    {
        "text": "when companies are developing training",
        "start": 1428.96,
        "duration": 3.12
    },
    {
        "text": "data there's a lot of human input that",
        "start": 1430.32,
        "duration": 4.44
    },
    {
        "text": "goes into how the filtering takes place",
        "start": 1432.08,
        "duration": 4.36
    },
    {
        "text": "and so we cannot just assume that you",
        "start": 1434.76,
        "duration": 3.72
    },
    {
        "text": "know all data is gussian and that's",
        "start": 1436.44,
        "duration": 3.359
    },
    {
        "text": "everything we'll use to train the next",
        "start": 1438.48,
        "duration": 3.84
    },
    {
        "text": "generation of models uh but as far as it",
        "start": 1439.799,
        "duration": 4.76
    },
    {
        "text": "comes to like synthetic data being the",
        "start": 1442.32,
        "duration": 4.4
    },
    {
        "text": "sole source of pre-training data for",
        "start": 1444.559,
        "duration": 4.041
    },
    {
        "text": "Next Generation models I'm quite bearish",
        "start": 1446.72,
        "duration": 3.8
    },
    {
        "text": "on that working out I don't know if you",
        "start": 1448.6,
        "duration": 3.28
    },
    {
        "text": "saw but there was a piece in Forbes",
        "start": 1450.52,
        "duration": 3.48
    },
    {
        "text": "yesterday and um they they surveyed a",
        "start": 1451.88,
        "duration": 3.12
    },
    {
        "text": "whole bunch of people working in",
        "start": 1454.0,
        "duration": 4.6
    },
    {
        "text": "corporations and 77% said that AI only",
        "start": 1455.0,
        "duration": 6.559
    },
    {
        "text": "complexified their jobs and you know was",
        "start": 1458.6,
        "duration": 4.439
    },
    {
        "text": "basically giving them more stress in",
        "start": 1461.559,
        "duration": 3.561
    },
    {
        "text": "their day-to-day",
        "start": 1463.039,
        "duration": 4.481
    },
    {
        "text": "existence I do not find that surprising",
        "start": 1465.12,
        "duration": 5.2
    },
    {
        "text": "frankly I I mean to be clear it it it",
        "start": 1467.52,
        "duration": 4.68
    },
    {
        "text": "might not be the case that AI is making",
        "start": 1470.32,
        "duration": 4.04
    },
    {
        "text": "the jobs worse it might just be the case",
        "start": 1472.2,
        "duration": 3.76
    },
    {
        "text": "that there are organizational dynamics",
        "start": 1474.36,
        "duration": 4.24
    },
    {
        "text": "that are also changing as a result of AI",
        "start": 1475.96,
        "duration": 4.8
    },
    {
        "text": "being introduced into ARs and so it",
        "start": 1478.6,
        "duration": 3.439
    },
    {
        "text": "might turn out to be the case that this",
        "start": 1480.76,
        "duration": 3.0
    },
    {
        "text": "is temporary but I think this also",
        "start": 1482.039,
        "duration": 3.321
    },
    {
        "text": "highlights this other Trend we've been",
        "start": 1483.76,
        "duration": 2.72
    },
    {
        "text": "seeing with the introduction of",
        "start": 1485.36,
        "duration": 3.72
    },
    {
        "text": "generative Ai and llms which is that",
        "start": 1486.48,
        "duration": 5.36
    },
    {
        "text": "there are a lot of externalities that AI",
        "start": 1489.08,
        "duration": 4.839
    },
    {
        "text": "companies themselves don't have to bear",
        "start": 1491.84,
        "duration": 3.52
    },
    {
        "text": "but that are imposed on other",
        "start": 1493.919,
        "duration": 3.601
    },
    {
        "text": "institutions so in corporations these",
        "start": 1495.36,
        "duration": 4.12
    },
    {
        "text": "are corporations that are using AI for",
        "start": 1497.52,
        "duration": 3.56
    },
    {
        "text": "profit driven reasons so perhaps that's",
        "start": 1499.48,
        "duration": 3.76
    },
    {
        "text": "okay but when it comes to institutions",
        "start": 1501.08,
        "duration": 4.4
    },
    {
        "text": "like schools um I mean I genuinely",
        "start": 1503.24,
        "duration": 3.919
    },
    {
        "text": "believe that AI has a place in our",
        "start": 1505.48,
        "duration": 3.72
    },
    {
        "text": "curricula I genuinely believe that if",
        "start": 1507.159,
        "duration": 4.041
    },
    {
        "text": "people are and students are taught how",
        "start": 1509.2,
        "duration": 4.4
    },
    {
        "text": "to learn AI well it will be extremely",
        "start": 1511.2,
        "duration": 4.4
    },
    {
        "text": "useful for the future careers and for",
        "start": 1513.6,
        "duration": 3.76
    },
    {
        "text": "their like thinking and writing skills",
        "start": 1515.6,
        "duration": 3.04
    },
    {
        "text": "many people say we should have none of",
        "start": 1517.36,
        "duration": 3.439
    },
    {
        "text": "it I quite strongly disagree with them",
        "start": 1518.64,
        "duration": 5.36
    },
    {
        "text": "in fact but the fact remains that the",
        "start": 1520.799,
        "duration": 5.721
    },
    {
        "text": "introduction of like chat GPT like tools",
        "start": 1524.0,
        "duration": 5.24
    },
    {
        "text": "has completely upended the curricul that",
        "start": 1526.52,
        "duration": 4.2
    },
    {
        "text": "um somewhat already overburdened",
        "start": 1529.24,
        "duration": 5.0
    },
    {
        "text": "teachers were already having to um deal",
        "start": 1530.72,
        "duration": 6.4
    },
    {
        "text": "with and and so basically we're in this",
        "start": 1534.24,
        "duration": 5.159
    },
    {
        "text": "state where a lot of organizational and",
        "start": 1537.12,
        "duration": 4.32
    },
    {
        "text": "institutional practices are changing and",
        "start": 1539.399,
        "duration": 4.681
    },
    {
        "text": "so some of the 77% of workers who said",
        "start": 1541.44,
        "duration": 4.8
    },
    {
        "text": "AI causes more stress might be reacting",
        "start": 1544.08,
        "duration": 4.0
    },
    {
        "text": "to these organizational Dynamics much",
        "start": 1546.24,
        "duration": 3.52
    },
    {
        "text": "more so than the introduction of AI",
        "start": 1548.08,
        "duration": 6.56
    },
    {
        "text": "itself does chat GPT make kids Dumber or",
        "start": 1549.76,
        "duration": 4.88
    },
    {
        "text": "smarter so chat gbd definitely makes me",
        "start": 1555.12,
        "duration": 5.439
    },
    {
        "text": "like a lot smarter in my day-to-day I",
        "start": 1558.32,
        "duration": 3.959
    },
    {
        "text": "would say half of the code half of the",
        "start": 1560.559,
        "duration": 3.561
    },
    {
        "text": "first draft of code that I write is now",
        "start": 1562.279,
        "duration": 4.161
    },
    {
        "text": "generated using a language model uh and",
        "start": 1564.12,
        "duration": 3.72
    },
    {
        "text": "that is that is saying something like I",
        "start": 1566.44,
        "duration": 2.719
    },
    {
        "text": "think for a lot of the recent work I've",
        "start": 1567.84,
        "duration": 3.4
    },
    {
        "text": "done I've had to write a lot of code um",
        "start": 1569.159,
        "duration": 4.64
    },
    {
        "text": "and the fact that I can sort of operate",
        "start": 1571.24,
        "duration": 4.28
    },
    {
        "text": "at a higher level of abstraction for the",
        "start": 1573.799,
        "duration": 4.36
    },
    {
        "text": "large part of writing code uh that",
        "start": 1575.52,
        "duration": 5.2
    },
    {
        "text": "really does change the equation like",
        "start": 1578.159,
        "duration": 4.281
    },
    {
        "text": "dramatically for me the other place",
        "start": 1580.72,
        "duration": 3.4
    },
    {
        "text": "where I really like to use tools like",
        "start": 1582.44,
        "duration": 4.479
    },
    {
        "text": "chat gbd is where the outputs are easily",
        "start": 1584.12,
        "duration": 5.48
    },
    {
        "text": "identifiable um so you can easily verify",
        "start": 1586.919,
        "duration": 4.401
    },
    {
        "text": "if an output is correct or not like my",
        "start": 1589.6,
        "duration": 4.199
    },
    {
        "text": "website is generated using chat GPD my",
        "start": 1591.32,
        "duration": 4.4
    },
    {
        "text": "resume is generated using chat GPD any",
        "start": 1593.799,
        "duration": 3.721
    },
    {
        "text": "place where you can easily verify the",
        "start": 1595.72,
        "duration": 4.4
    },
    {
        "text": "tool works or the output is correct uh",
        "start": 1597.52,
        "duration": 5.519
    },
    {
        "text": "is a is a great place to use use it yeah",
        "start": 1600.12,
        "duration": 4.559
    },
    {
        "text": "I agree with your take um I I talk about",
        "start": 1603.039,
        "duration": 3.24
    },
    {
        "text": "the understanding credit card quite a",
        "start": 1604.679,
        "duration": 3.761
    },
    {
        "text": "lot with chat GPT and I find if I",
        "start": 1606.279,
        "duration": 3.681
    },
    {
        "text": "already understand something then it's a",
        "start": 1608.44,
        "duration": 3.44
    },
    {
        "text": "great time sa but if I'm trying to",
        "start": 1609.96,
        "duration": 3.04
    },
    {
        "text": "understand something I don't yet",
        "start": 1611.88,
        "duration": 4.2
    },
    {
        "text": "understand then it's not um anyway you",
        "start": 1613.0,
        "duration": 4.76
    },
    {
        "text": "have written this really interesting",
        "start": 1616.08,
        "duration": 4.56
    },
    {
        "text": "paper on AI agents and maybe we should",
        "start": 1617.76,
        "duration": 4.32
    },
    {
        "text": "just start by saying you know like um",
        "start": 1620.64,
        "duration": 3.639
    },
    {
        "text": "we've been talking about agents and like",
        "start": 1622.08,
        "duration": 3.8
    },
    {
        "text": "you know multi-agent system distributed",
        "start": 1624.279,
        "duration": 3.52
    },
    {
        "text": "system server list for for years that",
        "start": 1625.88,
        "duration": 3.279
    },
    {
        "text": "there's always like you know big hype",
        "start": 1627.799,
        "duration": 4.0
    },
    {
        "text": "trains around technology do you think AI",
        "start": 1629.159,
        "duration": 3.921
    },
    {
        "text": "agents are",
        "start": 1631.799,
        "duration": 3.641
    },
    {
        "text": "different um I think it's hard it's very",
        "start": 1633.08,
        "duration": 5.64
    },
    {
        "text": "hard to say that uh AI agents it's very",
        "start": 1635.44,
        "duration": 5.0
    },
    {
        "text": "hard to evaluate the state of agents at",
        "start": 1638.72,
        "duration": 4.28
    },
    {
        "text": "this point to be honest um so so far",
        "start": 1640.44,
        "duration": 3.88
    },
    {
        "text": "what we've seen and what the paper was",
        "start": 1643.0,
        "duration": 3.399
    },
    {
        "text": "reacting to was that on the one hand we",
        "start": 1644.32,
        "duration": 4.16
    },
    {
        "text": "have claims that AI agents work really",
        "start": 1646.399,
        "duration": 4.801
    },
    {
        "text": "well for tasks like coding or answering",
        "start": 1648.48,
        "duration": 5.0
    },
    {
        "text": "questions factuality and so on and on",
        "start": 1651.2,
        "duration": 4.04
    },
    {
        "text": "the other hand when these agents have",
        "start": 1653.48,
        "duration": 4.16
    },
    {
        "text": "been deployed in the real world uh they",
        "start": 1655.24,
        "duration": 4.919
    },
    {
        "text": "have yet to make as much of an impact so",
        "start": 1657.64,
        "duration": 4.279
    },
    {
        "text": "we're trying to square these two very",
        "start": 1660.159,
        "duration": 3.841
    },
    {
        "text": "sort of uh different results in some",
        "start": 1661.919,
        "duration": 4.201
    },
    {
        "text": "sense and trying to see what goes on and",
        "start": 1664.0,
        "duration": 4.36
    },
    {
        "text": "the paper is somewhat cheekily titled AI",
        "start": 1666.12,
        "duration": 4.2
    },
    {
        "text": "agents that matter because we think that",
        "start": 1668.36,
        "duration": 3.439
    },
    {
        "text": "most AI agents that are deployed right",
        "start": 1670.32,
        "duration": 4.12
    },
    {
        "text": "now don't um and so we looked at why",
        "start": 1671.799,
        "duration": 4.201
    },
    {
        "text": "that is the case and found that you know",
        "start": 1674.44,
        "duration": 3.32
    },
    {
        "text": "there's a bunch of standardization and",
        "start": 1676.0,
        "duration": 4.0
    },
    {
        "text": "rep usability errors many of these",
        "start": 1677.76,
        "duration": 4.159
    },
    {
        "text": "agents that are deployed in research",
        "start": 1680.0,
        "duration": 3.64
    },
    {
        "text": "settings might not work in practice",
        "start": 1681.919,
        "duration": 3.041
    },
    {
        "text": "because they're just too expensive to",
        "start": 1683.64,
        "duration": 3.879
    },
    {
        "text": "run um and ultimately we just need a",
        "start": 1684.96,
        "duration": 4.68
    },
    {
        "text": "better state of AI evaluation to answer",
        "start": 1687.519,
        "duration": 3.561
    },
    {
        "text": "the question in the first place or even",
        "start": 1689.64,
        "duration": 3.879
    },
    {
        "text": "contemplate it yeah so you found that um",
        "start": 1691.08,
        "duration": 4.319
    },
    {
        "text": "simple baselines often outperform more",
        "start": 1693.519,
        "duration": 3.721
    },
    {
        "text": "complex agent architectures can can you",
        "start": 1695.399,
        "duration": 3.561
    },
    {
        "text": "tell us about that absolutely this is",
        "start": 1697.24,
        "duration": 3.08
    },
    {
        "text": "one of my favorite findings from the",
        "start": 1698.96,
        "duration": 5.24
    },
    {
        "text": "paper so um my co-author and my co-lead",
        "start": 1700.32,
        "duration": 6.16
    },
    {
        "text": "Benedict and I were looking at human",
        "start": 1704.2,
        "duration": 4.359
    },
    {
        "text": "eval and there had been claims that that",
        "start": 1706.48,
        "duration": 4.84
    },
    {
        "text": "human eval is basically like the top",
        "start": 1708.559,
        "duration": 5.12
    },
    {
        "text": "three leaderboard agents are all um",
        "start": 1711.32,
        "duration": 4.359
    },
    {
        "text": "complex agents they like reflect on",
        "start": 1713.679,
        "duration": 4.0
    },
    {
        "text": "their outputs uh they do some sort of",
        "start": 1715.679,
        "duration": 4.521
    },
    {
        "text": "debugging um and that's how they get to",
        "start": 1717.679,
        "duration": 5.561
    },
    {
        "text": "this impressively high performance um",
        "start": 1720.2,
        "duration": 5.199
    },
    {
        "text": "and what we tried to do instead was just",
        "start": 1723.24,
        "duration": 5.039
    },
    {
        "text": "to retry the outputs of an llm multiple",
        "start": 1725.399,
        "duration": 5.28
    },
    {
        "text": "times um this is not doing anything",
        "start": 1728.279,
        "duration": 4.921
    },
    {
        "text": "fancy there are some example test cases",
        "start": 1730.679,
        "duration": 4.521
    },
    {
        "text": "that are pro that are part of every",
        "start": 1733.2,
        "duration": 5.04
    },
    {
        "text": "human eval problem um if an llm fails to",
        "start": 1735.2,
        "duration": 4.479
    },
    {
        "text": "pass these test cases you just hit the",
        "start": 1738.24,
        "duration": 3.88
    },
    {
        "text": "reset button and retry again and what we",
        "start": 1739.679,
        "duration": 4.84
    },
    {
        "text": "found that this simple trick is enough",
        "start": 1742.12,
        "duration": 4.08
    },
    {
        "text": "to like essentially match the",
        "start": 1744.519,
        "duration": 3.681
    },
    {
        "text": "state-of-the-art when it comes to agent",
        "start": 1746.2,
        "duration": 5.4
    },
    {
        "text": "designs um so a lot of the community",
        "start": 1748.2,
        "duration": 5.479
    },
    {
        "text": "wisdom around agents seems to be",
        "start": 1751.6,
        "duration": 4.319
    },
    {
        "text": "centered on the fact that we can do",
        "start": 1753.679,
        "duration": 4.081
    },
    {
        "text": "reflection and reasoning and this type",
        "start": 1755.919,
        "duration": 3.76
    },
    {
        "text": "of sort of system to thinking if you",
        "start": 1757.76,
        "duration": 4.519
    },
    {
        "text": "will and that's what gets agents um to",
        "start": 1759.679,
        "duration": 5.0
    },
    {
        "text": "perform at a certain level but we're",
        "start": 1762.279,
        "duration": 3.961
    },
    {
        "text": "essentially challenging that hypothesis",
        "start": 1764.679,
        "duration": 3.201
    },
    {
        "text": "we're saying like look if we just retry",
        "start": 1766.24,
        "duration": 3.279
    },
    {
        "text": "it five times there is no system two",
        "start": 1767.88,
        "duration": 3.96
    },
    {
        "text": "here um and so so what's going on here",
        "start": 1769.519,
        "duration": 4.081
    },
    {
        "text": "and I think it also pushes Us in the",
        "start": 1771.84,
        "duration": 4.12
    },
    {
        "text": "direction of understanding agents better",
        "start": 1773.6,
        "duration": 3.72
    },
    {
        "text": "um is it really the case that there's",
        "start": 1775.96,
        "duration": 2.8
    },
    {
        "text": "reasoning going on or is it just the",
        "start": 1777.32,
        "duration": 2.88
    },
    {
        "text": "fact that you have more tries more",
        "start": 1778.76,
        "duration": 4.24
    },
    {
        "text": "tokens um but but yeah I mean basically",
        "start": 1780.2,
        "duration": 4.479
    },
    {
        "text": "empirically it does seem to be the case",
        "start": 1783.0,
        "duration": 3.88
    },
    {
        "text": "that retrying is an exceptionally solid",
        "start": 1784.679,
        "duration": 4.48
    },
    {
        "text": "Baseline and that anytime you say that a",
        "start": 1786.88,
        "duration": 4.44
    },
    {
        "text": "complex agent architecture is needed uh",
        "start": 1789.159,
        "duration": 4.561
    },
    {
        "text": "you must first compare it to a baseline",
        "start": 1791.32,
        "duration": 4.0
    },
    {
        "text": "um which essentially might cost like",
        "start": 1793.72,
        "duration": 4.12
    },
    {
        "text": "tens or hundreds of times lower um and",
        "start": 1795.32,
        "duration": 4.28
    },
    {
        "text": "that's that's that's the way to make uh",
        "start": 1797.84,
        "duration": 4.36
    },
    {
        "text": "meaningful comparison yeah so the um you",
        "start": 1799.6,
        "duration": 4.64
    },
    {
        "text": "know the cost trade-off was was a huge",
        "start": 1802.2,
        "duration": 4.56
    },
    {
        "text": "theme um in the paper how do you jointly",
        "start": 1804.24,
        "duration": 4.48
    },
    {
        "text": "optimize you know cost and and accuracy",
        "start": 1806.76,
        "duration": 5.08
    },
    {
        "text": "in agent design so um I'm a big fan of",
        "start": 1808.72,
        "duration": 6.52
    },
    {
        "text": "DSP DSP is this framework by Omar katab",
        "start": 1811.84,
        "duration": 5.719
    },
    {
        "text": "and others at Stanford and Berkeley uh",
        "start": 1815.24,
        "duration": 5.08
    },
    {
        "text": "that tries to optimize language model",
        "start": 1817.559,
        "duration": 5.401
    },
    {
        "text": "pipelines um it basically automatically",
        "start": 1820.32,
        "duration": 4.959
    },
    {
        "text": "Tunes The Prompt using language models",
        "start": 1822.96,
        "duration": 5.16
    },
    {
        "text": "um trains the model to input um few",
        "start": 1825.279,
        "duration": 5.801
    },
    {
        "text": "short examples that work best and so on",
        "start": 1828.12,
        "duration": 5.2
    },
    {
        "text": "um and Benedict and I are both big users",
        "start": 1831.08,
        "duration": 6.12
    },
    {
        "text": "of DSi so the way DSi works is that it",
        "start": 1833.32,
        "duration": 6.04
    },
    {
        "text": "tries to find few short examples and",
        "start": 1837.2,
        "duration": 4.8
    },
    {
        "text": "instructions for a given task um so",
        "start": 1839.36,
        "duration": 4.28
    },
    {
        "text": "let's say you want to solve a question",
        "start": 1842.0,
        "duration": 3.159
    },
    {
        "text": "answer problem that does retrieval",
        "start": 1843.64,
        "duration": 2.879
    },
    {
        "text": "augmented generation to answer the",
        "start": 1845.159,
        "duration": 3.681
    },
    {
        "text": "questions what is the search query that",
        "start": 1846.519,
        "duration": 4.201
    },
    {
        "text": "you want to use um in the retrieval",
        "start": 1848.84,
        "duration": 3.64
    },
    {
        "text": "system what is the prompt to the",
        "start": 1850.72,
        "duration": 3.6
    },
    {
        "text": "language model uh what are the few short",
        "start": 1852.48,
        "duration": 3.64
    },
    {
        "text": "examples that you should give to be able",
        "start": 1854.32,
        "duration": 4.64
    },
    {
        "text": "to generate nice search queries um one",
        "start": 1856.12,
        "duration": 5.88
    },
    {
        "text": "way to do that is by optimizing for",
        "start": 1858.96,
        "duration": 6.439
    },
    {
        "text": "accuracy so you can optimize uh on a",
        "start": 1862.0,
        "duration": 5.399
    },
    {
        "text": "large number of synthetic or manually",
        "start": 1865.399,
        "duration": 4.4
    },
    {
        "text": "created prompts and F short examples um",
        "start": 1867.399,
        "duration": 4.041
    },
    {
        "text": "and that leads to the you finding the",
        "start": 1869.799,
        "duration": 3.921
    },
    {
        "text": "best possible prompt um and you use that",
        "start": 1871.44,
        "duration": 3.719
    },
    {
        "text": "and perhaps in the production setting it",
        "start": 1873.72,
        "duration": 3.72
    },
    {
        "text": "does well so Omar has shown that uh you",
        "start": 1875.159,
        "duration": 4.4
    },
    {
        "text": "know DSi is really really good at",
        "start": 1877.44,
        "duration": 3.76
    },
    {
        "text": "finding these prompts that work way",
        "start": 1879.559,
        "duration": 2.84
    },
    {
        "text": "better than the current state-ofthe-art",
        "start": 1881.2,
        "duration": 3.76
    },
    {
        "text": "um they can improve the performance of",
        "start": 1882.399,
        "duration": 5.24
    },
    {
        "text": "like small models like llama 8B to",
        "start": 1884.96,
        "duration": 5.439
    },
    {
        "text": "essent entially match um competitively",
        "start": 1887.639,
        "duration": 6.0
    },
    {
        "text": "with um gp4 level models what we wanted",
        "start": 1890.399,
        "duration": 6.201
    },
    {
        "text": "to do do was we wanted to jointly",
        "start": 1893.639,
        "duration": 6.081
    },
    {
        "text": "optimize cost as well as accuracy so",
        "start": 1896.6,
        "duration": 5.319
    },
    {
        "text": "instead of cost uh sorry instead of",
        "start": 1899.72,
        "duration": 5.0
    },
    {
        "text": "accuracy being the sole metric by which",
        "start": 1901.919,
        "duration": 5.161
    },
    {
        "text": "we evaluate how well a given prompt and",
        "start": 1904.72,
        "duration": 4.52
    },
    {
        "text": "a set of f shot examples work we also",
        "start": 1907.08,
        "duration": 3.959
    },
    {
        "text": "wanted to look at how much it costs so",
        "start": 1909.24,
        "duration": 3.679
    },
    {
        "text": "what is the token length um and can we",
        "start": 1911.039,
        "duration": 3.64
    },
    {
        "text": "reduce this token length without taking",
        "start": 1912.919,
        "duration": 4.48
    },
    {
        "text": "hits on accuracy so we modified the DS",
        "start": 1914.679,
        "duration": 5.84
    },
    {
        "text": "by frame work to work also with um the",
        "start": 1917.399,
        "duration": 6.52
    },
    {
        "text": "token cost of an llm call um and like",
        "start": 1920.519,
        "duration": 5.561
    },
    {
        "text": "the specific optimization was very",
        "start": 1923.919,
        "duration": 3.36
    },
    {
        "text": "simple it was like a discrete",
        "start": 1926.08,
        "duration": 2.8
    },
    {
        "text": "optimization method we implemented we",
        "start": 1927.279,
        "duration": 3.64
    },
    {
        "text": "sure we can do better uh but what we",
        "start": 1928.88,
        "duration": 4.159
    },
    {
        "text": "found was essentially just implementing",
        "start": 1930.919,
        "duration": 4.561
    },
    {
        "text": "the simple method we came up with um can",
        "start": 1933.039,
        "duration": 5.36
    },
    {
        "text": "reduce the cost by half um while still",
        "start": 1935.48,
        "duration": 4.88
    },
    {
        "text": "maintaining accuracy so now you can have",
        "start": 1938.399,
        "duration": 5.441
    },
    {
        "text": "like llama 3 level models or uh like",
        "start": 1940.36,
        "duration": 6.72
    },
    {
        "text": "basically essentially matching gp4 at",
        "start": 1943.84,
        "duration": 6.48
    },
    {
        "text": "like one0 the cost amazing amazing",
        "start": 1947.08,
        "duration": 4.88
    },
    {
        "text": "what's the distinction between model",
        "start": 1950.32,
        "duration": 3.8
    },
    {
        "text": "evaluation and downstream performance",
        "start": 1951.96,
        "duration": 3.88
    },
    {
        "text": "that's a great question so model",
        "start": 1954.12,
        "duration": 4.679
    },
    {
        "text": "evaluation is like evaluation that we",
        "start": 1955.84,
        "duration": 4.439
    },
    {
        "text": "all do with like language models to",
        "start": 1958.799,
        "duration": 2.961
    },
    {
        "text": "evaluate how well a model can solve a",
        "start": 1960.279,
        "duration": 3.4
    },
    {
        "text": "reasoning task how well it can solve",
        "start": 1961.76,
        "duration": 3.72
    },
    {
        "text": "let's say a math task a coding task and",
        "start": 1963.679,
        "duration": 4.12
    },
    {
        "text": "so on and the purpose of model",
        "start": 1965.48,
        "duration": 4.559
    },
    {
        "text": "evaluation is to compare two models",
        "start": 1967.799,
        "duration": 4.641
    },
    {
        "text": "against each other uh it could be to",
        "start": 1970.039,
        "duration": 4.12
    },
    {
        "text": "compare if models have improved in",
        "start": 1972.44,
        "duration": 4.32
    },
    {
        "text": "capabilities as a regression test to see",
        "start": 1974.159,
        "duration": 4.921
    },
    {
        "text": "that models don't uh decate version over",
        "start": 1976.76,
        "duration": 4.759
    },
    {
        "text": "version and so on um on the other hand",
        "start": 1979.08,
        "duration": 4.04
    },
    {
        "text": "Downstream evaluation is completely",
        "start": 1981.519,
        "duration": 4.64
    },
    {
        "text": "different so Downstream evaluation um is",
        "start": 1983.12,
        "duration": 4.76
    },
    {
        "text": "evaluation from the perspective of an",
        "start": 1986.159,
        "duration": 4.36
    },
    {
        "text": "end user who might be using a system",
        "start": 1987.88,
        "duration": 4.96
    },
    {
        "text": "based on this language model to perform",
        "start": 1990.519,
        "duration": 4.0
    },
    {
        "text": "a specific task that they are actually",
        "start": 1992.84,
        "duration": 5.439
    },
    {
        "text": "interested in um so in in as an analogy",
        "start": 1994.519,
        "duration": 6.081
    },
    {
        "text": "I think U an engine developer like",
        "start": 1998.279,
        "duration": 5.041
    },
    {
        "text": "rollsroyce build Ling airplane engines",
        "start": 2000.6,
        "duration": 4.559
    },
    {
        "text": "might be construct conducting model",
        "start": 2003.32,
        "duration": 3.839
    },
    {
        "text": "evaluations when they're uh the",
        "start": 2005.159,
        "duration": 3.441
    },
    {
        "text": "equivalent of mod evaluations when",
        "start": 2007.159,
        "duration": 3.76
    },
    {
        "text": "they're regression testing their systems",
        "start": 2008.6,
        "duration": 4.079
    },
    {
        "text": "but um Boeing when they're building",
        "start": 2010.919,
        "duration": 3.321
    },
    {
        "text": "their aircraft are interested in how",
        "start": 2012.679,
        "duration": 3.84
    },
    {
        "text": "well the aircraft as a whole performs um",
        "start": 2014.24,
        "duration": 5.08
    },
    {
        "text": "they do not really care about whether",
        "start": 2016.519,
        "duration": 5.601
    },
    {
        "text": "like a specific model has like the high",
        "start": 2019.32,
        "duration": 5.52
    },
    {
        "text": "throughput or whatever uh in so far as",
        "start": 2022.12,
        "duration": 4.279
    },
    {
        "text": "um that's their end goal that's not",
        "start": 2024.84,
        "duration": 3.6
    },
    {
        "text": "their end goal really what they really",
        "start": 2026.399,
        "duration": 3.441
    },
    {
        "text": "care about is the performance of the",
        "start": 2028.44,
        "duration": 3.56
    },
    {
        "text": "overall system and I think the same",
        "start": 2029.84,
        "duration": 4.64
    },
    {
        "text": "holds true for um AI systems as well so",
        "start": 2032.0,
        "duration": 4.32
    },
    {
        "text": "a person making a search engine using an",
        "start": 2034.48,
        "duration": 4.079
    },
    {
        "text": "llm should care about whether the search",
        "start": 2036.32,
        "duration": 4.599
    },
    {
        "text": "engine has desirable properties not",
        "start": 2038.559,
        "duration": 4.6
    },
    {
        "text": "whether uh the model itself has high",
        "start": 2040.919,
        "duration": 5.76
    },
    {
        "text": "reasoning capabilities um the somewhat",
        "start": 2043.159,
        "duration": 5.76
    },
    {
        "text": "sad thing is in the community I think we",
        "start": 2046.679,
        "duration": 3.601
    },
    {
        "text": "we've tended to conflate model",
        "start": 2048.919,
        "duration": 4.081
    },
    {
        "text": "evaluation with Downstream evaluation so",
        "start": 2050.28,
        "duration": 6.0
    },
    {
        "text": "in many cases uh we see model developers",
        "start": 2053.0,
        "duration": 5.32
    },
    {
        "text": "claiming that their models are better at",
        "start": 2056.28,
        "duration": 5.24
    },
    {
        "text": "Downstream tasks um and like let's say",
        "start": 2058.32,
        "duration": 5.599
    },
    {
        "text": "they're more cost efficient um than at",
        "start": 2061.52,
        "duration": 4.52
    },
    {
        "text": "Downstream tasks when actually what they",
        "start": 2063.919,
        "duration": 5.081
    },
    {
        "text": "should be comparing is um like what do",
        "start": 2066.04,
        "duration": 5.0
    },
    {
        "text": "the downstream metrics really reveal how",
        "start": 2069.0,
        "duration": 4.159
    },
    {
        "text": "much does it actually cost so one",
        "start": 2071.04,
        "duration": 4.68
    },
    {
        "text": "egregious example of this is um",
        "start": 2073.159,
        "duration": 5.641
    },
    {
        "text": "mistral's branding of um how well their",
        "start": 2075.72,
        "duration": 5.56
    },
    {
        "text": "models perform so I'm not sure if you've",
        "start": 2078.8,
        "duration": 4.24
    },
    {
        "text": "seen this but every time mistl releases",
        "start": 2081.28,
        "duration": 3.96
    },
    {
        "text": "a new model uh they essentially come up",
        "start": 2083.04,
        "duration": 5.879
    },
    {
        "text": "with a parito curve um on the y- axis is",
        "start": 2085.24,
        "duration": 7.2
    },
    {
        "text": "like the MML U score on the x-axis is um",
        "start": 2088.919,
        "duration": 5.601
    },
    {
        "text": "the number of parameters and I think",
        "start": 2092.44,
        "duration": 3.399
    },
    {
        "text": "that's where the real slide of hand",
        "start": 2094.52,
        "duration": 4.079
    },
    {
        "text": "happens because Downstream users have",
        "start": 2095.839,
        "duration": 4.441
    },
    {
        "text": "like no interest in what the number of",
        "start": 2098.599,
        "duration": 5.441
    },
    {
        "text": "active parameters in uh in Ane model is",
        "start": 2100.28,
        "duration": 6.28
    },
    {
        "text": "um and so mistl essentially claims that",
        "start": 2104.04,
        "duration": 4.96
    },
    {
        "text": "oh like in the myal 8 cross 7B model the",
        "start": 2106.56,
        "duration": 4.48
    },
    {
        "text": "number of Downstream parameters is less",
        "start": 2109.0,
        "duration": 3.72
    },
    {
        "text": "than the number of Downstream parameters",
        "start": 2111.04,
        "duration": 4.4
    },
    {
        "text": "in Lama 2113b but when you look at the",
        "start": 2112.72,
        "duration": 4.52
    },
    {
        "text": "costs of generating tokens using both of",
        "start": 2115.44,
        "duration": 4.8
    },
    {
        "text": "these models uh Lama 213b is way cheaper",
        "start": 2117.24,
        "duration": 4.76
    },
    {
        "text": "because it has fewer memory requirements",
        "start": 2120.24,
        "duration": 4.359
    },
    {
        "text": "and so on and that's the essential",
        "start": 2122.0,
        "duration": 4.76
    },
    {
        "text": "metric that model developers are often",
        "start": 2124.599,
        "duration": 4.961
    },
    {
        "text": "missing when it comes to um the actual",
        "start": 2126.76,
        "duration": 4.839
    },
    {
        "text": "cost of running models and we've seen",
        "start": 2129.56,
        "duration": 4.44
    },
    {
        "text": "this repeated in many cases sometimes it",
        "start": 2131.599,
        "duration": 4.801
    },
    {
        "text": "makes sense to sort of have different",
        "start": 2134.0,
        "duration": 5.359
    },
    {
        "text": "cost estimates so if you are actually uh",
        "start": 2136.4,
        "duration": 5.32
    },
    {
        "text": "interested in the compute efficiency of",
        "start": 2139.359,
        "duration": 4.48
    },
    {
        "text": "your model training runs then it makes",
        "start": 2141.72,
        "duration": 4.359
    },
    {
        "text": "sense to replace the cost access with",
        "start": 2143.839,
        "duration": 4.481
    },
    {
        "text": "the number of flops for example but from",
        "start": 2146.079,
        "duration": 3.961
    },
    {
        "text": "the perspective of Downstream users this",
        "start": 2148.32,
        "duration": 4.12
    },
    {
        "text": "is rarely the case like the main bottom",
        "start": 2150.04,
        "duration": 4.76
    },
    {
        "text": "line metric for most Downstream users is",
        "start": 2152.44,
        "duration": 4.2
    },
    {
        "text": "actual dollar cost and that's the thing",
        "start": 2154.8,
        "duration": 3.88
    },
    {
        "text": "that's often ignored now there are good",
        "start": 2156.64,
        "duration": 4.28
    },
    {
        "text": "reasons for ignoring this as well um you",
        "start": 2158.68,
        "duration": 4.12
    },
    {
        "text": "know Downstream costs for the same model",
        "start": 2160.92,
        "duration": 4.679
    },
    {
        "text": "might go down over time uh some models",
        "start": 2162.8,
        "duration": 4.48
    },
    {
        "text": "might never be made available again",
        "start": 2165.599,
        "duration": 4.601
    },
    {
        "text": "there might be sort of changes to uh the",
        "start": 2167.28,
        "duration": 4.48
    },
    {
        "text": "price of a model depending on which",
        "start": 2170.2,
        "duration": 3.32
    },
    {
        "text": "provider you use it from so like",
        "start": 2171.76,
        "duration": 3.359
    },
    {
        "text": "together has a different cost from any",
        "start": 2173.52,
        "duration": 4.799
    },
    {
        "text": "scale when you use Lama models I think",
        "start": 2175.119,
        "duration": 5.521
    },
    {
        "text": "despite these issues it's still worth",
        "start": 2178.319,
        "duration": 4.8
    },
    {
        "text": "looking at Cost because in all of these",
        "start": 2180.64,
        "duration": 4.56
    },
    {
        "text": "cases like the price is going down over",
        "start": 2183.119,
        "duration": 4.681
    },
    {
        "text": "time for example this actually meaning",
        "start": 2185.2,
        "duration": 4.96
    },
    {
        "text": "changes the experience of a developer um",
        "start": 2187.8,
        "duration": 4.2
    },
    {
        "text": "and so if we do want to measure like how",
        "start": 2190.16,
        "duration": 4.12
    },
    {
        "text": "a downstream developer would react to",
        "start": 2192.0,
        "duration": 4.599
    },
    {
        "text": "prices going down over time um it really",
        "start": 2194.28,
        "duration": 4.88
    },
    {
        "text": "does matter if providers um are reducing",
        "start": 2196.599,
        "duration": 4.561
    },
    {
        "text": "costs if computer is getting cheaper and",
        "start": 2199.16,
        "duration": 3.56
    },
    {
        "text": "so in some sense I would say it's a",
        "start": 2201.16,
        "duration": 4.159
    },
    {
        "text": "feature and not a bug of evaluating cost",
        "start": 2202.72,
        "duration": 4.76
    },
    {
        "text": "and that's the main using that as the",
        "start": 2205.319,
        "duration": 4.361
    },
    {
        "text": "main metric for Downstream evaluation",
        "start": 2207.48,
        "duration": 3.44
    },
    {
        "text": "you also spoke about the dreaded",
        "start": 2209.68,
        "duration": 3.84
    },
    {
        "text": "shortcut problem in metrics tell us",
        "start": 2210.92,
        "duration": 5.439
    },
    {
        "text": "about that absolutely um so shortcuts",
        "start": 2213.52,
        "duration": 5.319
    },
    {
        "text": "have been like a problem for ML research",
        "start": 2216.359,
        "duration": 4.48
    },
    {
        "text": "for a long time uh there's a create",
        "start": 2218.839,
        "duration": 4.161
    },
    {
        "text": "paper that I really like called shortcut",
        "start": 2220.839,
        "duration": 4.361
    },
    {
        "text": "learning in deep neural networks which",
        "start": 2223.0,
        "duration": 3.88
    },
    {
        "text": "basically shows how neural networks are",
        "start": 2225.2,
        "duration": 4.2
    },
    {
        "text": "likely to take shortcuts um like you",
        "start": 2226.88,
        "duration": 3.84
    },
    {
        "text": "know relying on the color of the",
        "start": 2229.4,
        "duration": 3.679
    },
    {
        "text": "background for identifying species in an",
        "start": 2230.72,
        "duration": 5.52
    },
    {
        "text": "image or whatever um and in the paper we",
        "start": 2233.079,
        "duration": 5.641
    },
    {
        "text": "point out that agent evaluations are",
        "start": 2236.24,
        "duration": 5.56
    },
    {
        "text": "extremely prone to shortcut learning um",
        "start": 2238.72,
        "duration": 4.96
    },
    {
        "text": "and in particular that's because when it",
        "start": 2241.8,
        "duration": 4.12
    },
    {
        "text": "comes to agent evals we've sort of given",
        "start": 2243.68,
        "duration": 5.32
    },
    {
        "text": "up on the principles of good evaluation",
        "start": 2245.92,
        "duration": 5.36
    },
    {
        "text": "um so one of the sort of standard",
        "start": 2249.0,
        "duration": 4.599
    },
    {
        "text": "principles of building an ml evaluation",
        "start": 2251.28,
        "duration": 4.96
    },
    {
        "text": "is having a heldout test set I think",
        "start": 2253.599,
        "duration": 5.361
    },
    {
        "text": "this assumption has led the ml field",
        "start": 2256.24,
        "duration": 5.079
    },
    {
        "text": "forward many times over in the last 50",
        "start": 2258.96,
        "duration": 5.24
    },
    {
        "text": "years uh David Dono at Stanford calls it",
        "start": 2261.319,
        "duration": 5.081
    },
    {
        "text": "the miracle success uh and basically",
        "start": 2264.2,
        "duration": 3.399
    },
    {
        "text": "attributes all of this miracle",
        "start": 2266.4,
        "duration": 3.48
    },
    {
        "text": "miraculous success of ml to the fact",
        "start": 2267.599,
        "duration": 4.76
    },
    {
        "text": "that we have this common task framework",
        "start": 2269.88,
        "duration": 4.84
    },
    {
        "text": "uh and held out test sets um when it",
        "start": 2272.359,
        "duration": 4.201
    },
    {
        "text": "comes to agent benchmarks uh we",
        "start": 2274.72,
        "duration": 3.32
    },
    {
        "text": "basically looked at like over a dozen",
        "start": 2276.56,
        "duration": 3.559
    },
    {
        "text": "benchmarks and in most cases there is no",
        "start": 2278.04,
        "duration": 5.16
    },
    {
        "text": "held out test set um now there are many",
        "start": 2280.119,
        "duration": 5.2
    },
    {
        "text": "ways that agents could abuse this type",
        "start": 2283.2,
        "duration": 4.48
    },
    {
        "text": "of um like lack of heldout the simplest",
        "start": 2285.319,
        "duration": 4.52
    },
    {
        "text": "way would be that we build an agent that",
        "start": 2287.68,
        "duration": 3.88
    },
    {
        "text": "has access to a lookup table with the",
        "start": 2289.839,
        "duration": 3.721
    },
    {
        "text": "solution U you can actually do that",
        "start": 2291.56,
        "duration": 3.48
    },
    {
        "text": "today just like feed in all of the",
        "start": 2293.56,
        "duration": 3.519
    },
    {
        "text": "answers into a hash table all the agent",
        "start": 2295.04,
        "duration": 3.559
    },
    {
        "text": "has to do is retrieve the answers that",
        "start": 2297.079,
        "duration": 3.04
    },
    {
        "text": "would be a legitimate solution to many",
        "start": 2298.599,
        "duration": 3.361
    },
    {
        "text": "of these agents now of course this is an",
        "start": 2300.119,
        "duration": 4.121
    },
    {
        "text": "exaggeration like no agent developer is",
        "start": 2301.96,
        "duration": 3.84
    },
    {
        "text": "going to do that but there are many",
        "start": 2304.24,
        "duration": 3.28
    },
    {
        "text": "subtle ways in which agents can learn",
        "start": 2305.8,
        "duration": 3.6
    },
    {
        "text": "learn to do that even if we don't",
        "start": 2307.52,
        "duration": 4.079
    },
    {
        "text": "explicitly feed it in um they can be",
        "start": 2309.4,
        "duration": 3.88
    },
    {
        "text": "human in the loop overfitting as some",
        "start": 2311.599,
        "duration": 3.72
    },
    {
        "text": "people call it so we sort of tweak our",
        "start": 2313.28,
        "duration": 3.48
    },
    {
        "text": "agents until they get a very high",
        "start": 2315.319,
        "duration": 3.641
    },
    {
        "text": "accuracy on a benchmark but all that's",
        "start": 2316.76,
        "duration": 4.359
    },
    {
        "text": "doing is feeding in the test set and",
        "start": 2318.96,
        "duration": 4.24
    },
    {
        "text": "information about what's in the test set",
        "start": 2321.119,
        "duration": 4.681
    },
    {
        "text": "um so so this is like one of the main um",
        "start": 2323.2,
        "duration": 5.28
    },
    {
        "text": "challenges with evaluation there's also",
        "start": 2325.8,
        "duration": 5.44
    },
    {
        "text": "the challenge of having a held out set",
        "start": 2328.48,
        "duration": 5.72
    },
    {
        "text": "at the right level of generality so in",
        "start": 2331.24,
        "duration": 5.079
    },
    {
        "text": "many cases people are claiming to make",
        "start": 2334.2,
        "duration": 4.44
    },
    {
        "text": "domain General agents like web agents",
        "start": 2336.319,
        "duration": 4.601
    },
    {
        "text": "that can basically do anything on the",
        "start": 2338.64,
        "duration": 4.52
    },
    {
        "text": "internet um but when it comes to these",
        "start": 2340.92,
        "duration": 4.48
    },
    {
        "text": "web agents I think the task of creating",
        "start": 2343.16,
        "duration": 5.159
    },
    {
        "text": "a h out test set becomes even harder",
        "start": 2345.4,
        "duration": 5.0
    },
    {
        "text": "because you might have cases where let's",
        "start": 2348.319,
        "duration": 4.8
    },
    {
        "text": "say a web agent Benchmark has eight",
        "start": 2350.4,
        "duration": 4.76
    },
    {
        "text": "different websites like an e-commerce",
        "start": 2353.119,
        "duration": 4.2
    },
    {
        "text": "website and an email website and a",
        "start": 2355.16,
        "duration": 4.48
    },
    {
        "text": "travel planner uh and a coding website",
        "start": 2357.319,
        "duration": 5.241
    },
    {
        "text": "and so on but if all of these different",
        "start": 2359.64,
        "duration": 5.84
    },
    {
        "text": "types of websites are made available and",
        "start": 2362.56,
        "duration": 4.92
    },
    {
        "text": "like the agent developer knows which",
        "start": 2365.48,
        "duration": 3.839
    },
    {
        "text": "size websites are included in the",
        "start": 2367.48,
        "duration": 4.2
    },
    {
        "text": "Benchmark then already like half of the",
        "start": 2369.319,
        "duration": 5.161
    },
    {
        "text": "challenge of the open web um is sort of",
        "start": 2371.68,
        "duration": 5.439
    },
    {
        "text": "circumvented because on the open web um",
        "start": 2374.48,
        "duration": 4.32
    },
    {
        "text": "the agent would never know what clicking",
        "start": 2377.119,
        "duration": 3.361
    },
    {
        "text": "on a link will lead to they might be led",
        "start": 2378.8,
        "duration": 3.64
    },
    {
        "text": "to a completely different website that's",
        "start": 2380.48,
        "duration": 4.04
    },
    {
        "text": "not in their domain and so when we're",
        "start": 2382.44,
        "duration": 3.6
    },
    {
        "text": "making statements like we have built",
        "start": 2384.52,
        "duration": 4.04
    },
    {
        "text": "generalist web agents based on um these",
        "start": 2386.04,
        "duration": 4.84
    },
    {
        "text": "sort of very specific um agent",
        "start": 2388.56,
        "duration": 4.559
    },
    {
        "text": "benchmarks we are likely to be misled",
        "start": 2390.88,
        "duration": 4.64
    },
    {
        "text": "into thinking we have uh extremely",
        "start": 2393.119,
        "duration": 4.921
    },
    {
        "text": "useful and capable agents uh whereas in",
        "start": 2395.52,
        "duration": 4.24
    },
    {
        "text": "reality these agents might not work well",
        "start": 2398.04,
        "duration": 3.76
    },
    {
        "text": "at all yeah I mean quick aside I love",
        "start": 2399.76,
        "duration": 3.52
    },
    {
        "text": "that shortcut learning paper everyone at",
        "start": 2401.8,
        "duration": 2.519
    },
    {
        "text": "home should read that paper it's",
        "start": 2403.28,
        "duration": 2.44
    },
    {
        "text": "absolutely amazing we should be thinking",
        "start": 2404.319,
        "duration": 3.961
    },
    {
        "text": "more about the the spectrum of non-rust",
        "start": 2405.72,
        "duration": 4.599
    },
    {
        "text": "generalization but um you spoke about",
        "start": 2408.28,
        "duration": 3.96
    },
    {
        "text": "the lack of standardization in in agent",
        "start": 2410.319,
        "duration": 4.201
    },
    {
        "text": "evaluations as well can you talk to that",
        "start": 2412.24,
        "duration": 4.44
    },
    {
        "text": "absolutely so one of the things we found",
        "start": 2414.52,
        "duration": 3.44
    },
    {
        "text": "out when we were conducting these",
        "start": 2416.68,
        "duration": 4.399
    },
    {
        "text": "evaluations is that many evaluation",
        "start": 2417.96,
        "duration": 5.32
    },
    {
        "text": "benchmarks do not come with like a",
        "start": 2421.079,
        "duration": 4.04
    },
    {
        "text": "standardized way to evaluate on The",
        "start": 2423.28,
        "duration": 4.0
    },
    {
        "text": "Benchmark so you might have a bench",
        "start": 2425.119,
        "duration": 5.0
    },
    {
        "text": "Benchmark with like a thousand tasks but",
        "start": 2427.28,
        "duration": 4.76
    },
    {
        "text": "all the Benchmark developer is providing",
        "start": 2430.119,
        "duration": 4.441
    },
    {
        "text": "is the list of tasks how to conduct",
        "start": 2432.04,
        "duration": 4.68
    },
    {
        "text": "evaluation on those thousand tasks is",
        "start": 2434.56,
        "duration": 4.6
    },
    {
        "text": "left up to the agent developers now what",
        "start": 2436.72,
        "duration": 4.72
    },
    {
        "text": "this means in practice is that an agent",
        "start": 2439.16,
        "duration": 5.6
    },
    {
        "text": "developer might um skip some tasks they",
        "start": 2441.44,
        "duration": 5.24
    },
    {
        "text": "might sort of remove five tasks that",
        "start": 2444.76,
        "duration": 5.079
    },
    {
        "text": "they feel are um like not working or",
        "start": 2446.68,
        "duration": 5.639
    },
    {
        "text": "have some issues they might change the",
        "start": 2449.839,
        "duration": 4.48
    },
    {
        "text": "tasks so since the tasks are available",
        "start": 2452.319,
        "duration": 3.921
    },
    {
        "text": "openly they might sort of modify the",
        "start": 2454.319,
        "duration": 4.241
    },
    {
        "text": "tasks to change the structure change the",
        "start": 2456.24,
        "duration": 4.359
    },
    {
        "text": "order and we've seen that llms are",
        "start": 2458.56,
        "duration": 4.4
    },
    {
        "text": "extremely sensitive to how information",
        "start": 2460.599,
        "duration": 4.561
    },
    {
        "text": "is presented to them prompt sensitivity",
        "start": 2462.96,
        "duration": 4.52
    },
    {
        "text": "is a huge issue for evaluation so when",
        "start": 2465.16,
        "duration": 4.64
    },
    {
        "text": "we give agent developers all of these",
        "start": 2467.48,
        "duration": 5.24
    },
    {
        "text": "degrees of freedom in a way we're also",
        "start": 2469.8,
        "duration": 4.76
    },
    {
        "text": "diluting the impact of these evals",
        "start": 2472.72,
        "duration": 3.96
    },
    {
        "text": "because when two agent developers say",
        "start": 2474.56,
        "duration": 3.559
    },
    {
        "text": "they have a certain accuracy on a",
        "start": 2476.68,
        "duration": 4.2
    },
    {
        "text": "benchmark that does not mean the same",
        "start": 2478.119,
        "duration": 5.281
    },
    {
        "text": "thing okay and the other thing is um",
        "start": 2480.88,
        "duration": 4.08
    },
    {
        "text": "this is really important you spoke about",
        "start": 2483.4,
        "duration": 3.679
    },
    {
        "text": "humans in the loop can can you bring",
        "start": 2484.96,
        "duration": 4.48
    },
    {
        "text": "that how important is that yeah",
        "start": 2487.079,
        "duration": 4.401
    },
    {
        "text": "absolutely so I mean I think humans in",
        "start": 2489.44,
        "duration": 4.919
    },
    {
        "text": "the loop can both lead to overestimating",
        "start": 2491.48,
        "duration": 4.359
    },
    {
        "text": "as well as underestimating the",
        "start": 2494.359,
        "duration": 4.521
    },
    {
        "text": "capabilities of AI agents um so they can",
        "start": 2495.839,
        "duration": 4.681
    },
    {
        "text": "overestimate the capability like I",
        "start": 2498.88,
        "duration": 3.12
    },
    {
        "text": "mentioned they can be human in the loop",
        "start": 2500.52,
        "duration": 3.76
    },
    {
        "text": "overfitting um a human is literally",
        "start": 2502.0,
        "duration": 4.72
    },
    {
        "text": "coding in even indirectly all of the",
        "start": 2504.28,
        "duration": 5.039
    },
    {
        "text": "tasks in a benchmark test set um into",
        "start": 2506.72,
        "duration": 4.24
    },
    {
        "text": "the agent and that makes for",
        "start": 2509.319,
        "duration": 4.04
    },
    {
        "text": "artificially high performance but I",
        "start": 2510.96,
        "duration": 4.2
    },
    {
        "text": "think something that's often missed that",
        "start": 2513.359,
        "duration": 3.48
    },
    {
        "text": "is that humans in the loop can also lead",
        "start": 2515.16,
        "duration": 4.0
    },
    {
        "text": "to us underestimating how well an agent",
        "start": 2516.839,
        "duration": 4.0
    },
    {
        "text": "can do in the real world and that's",
        "start": 2519.16,
        "duration": 3.199
    },
    {
        "text": "because when you think of yourselves",
        "start": 2520.839,
        "duration": 3.641
    },
    {
        "text": "using like an AI agent like GitHub",
        "start": 2522.359,
        "duration": 4.0
    },
    {
        "text": "copilot we're always in the loop giving",
        "start": 2524.48,
        "duration": 3.2
    },
    {
        "text": "it feedback so if there's something",
        "start": 2526.359,
        "duration": 3.921
    },
    {
        "text": "that's obviously wrong we can say maybe",
        "start": 2527.68,
        "duration": 4.76
    },
    {
        "text": "that doesn't look like right try again",
        "start": 2530.28,
        "duration": 4.36
    },
    {
        "text": "so and and what we've done with that one",
        "start": 2532.44,
        "duration": 4.32
    },
    {
        "text": "sentence of feedback is we've turned",
        "start": 2534.64,
        "duration": 4.4
    },
    {
        "text": "pass at one accuracy into pass at two",
        "start": 2536.76,
        "duration": 4.64
    },
    {
        "text": "accuracy uh which are like dramatically",
        "start": 2539.04,
        "duration": 4.68
    },
    {
        "text": "different for AI agents uh and we've",
        "start": 2541.4,
        "duration": 3.919
    },
    {
        "text": "we've repeatedly seen that retrying",
        "start": 2543.72,
        "duration": 3.48
    },
    {
        "text": "multiple times is an effective way to",
        "start": 2545.319,
        "duration": 4.52
    },
    {
        "text": "drastically improve accuracy now one of",
        "start": 2547.2,
        "duration": 4.8
    },
    {
        "text": "my favorite examples of this is a",
        "start": 2549.839,
        "duration": 5.52
    },
    {
        "text": "qualitative study um that was done by my",
        "start": 2552.0,
        "duration": 5.4
    },
    {
        "text": "colleagues at Princeton University where",
        "start": 2555.359,
        "duration": 3.921
    },
    {
        "text": "they looked at the usako Benchmark it's",
        "start": 2557.4,
        "duration": 5.24
    },
    {
        "text": "a coding Olympiad Benchmark based on um",
        "start": 2559.28,
        "duration": 6.44
    },
    {
        "text": "real problems from these olympiads and",
        "start": 2562.64,
        "duration": 5.08
    },
    {
        "text": "uh they looked at a small test set of",
        "start": 2565.72,
        "duration": 4.56
    },
    {
        "text": "like about 15 problems I think where a",
        "start": 2567.72,
        "duration": 4.04
    },
    {
        "text": "human could provide some basic",
        "start": 2570.28,
        "duration": 3.96
    },
    {
        "text": "rudimentary feedback to an llm agent",
        "start": 2571.76,
        "duration": 5.72
    },
    {
        "text": "based on where it went wrong um GPD 4",
        "start": 2574.24,
        "duration": 5.0
    },
    {
        "text": "and most other models had an accuracy of",
        "start": 2577.48,
        "duration": 4.72
    },
    {
        "text": "close to 0% when there was no feedback",
        "start": 2579.24,
        "duration": 5.24
    },
    {
        "text": "uh from a human um when there was",
        "start": 2582.2,
        "duration": 4.119
    },
    {
        "text": "feedback from a human the accuracy of",
        "start": 2584.48,
        "duration": 4.72
    },
    {
        "text": "GPD 4 went up to 86% and mind you this",
        "start": 2586.319,
        "duration": 5.401
    },
    {
        "text": "is very simple feedback in the form of",
        "start": 2589.2,
        "duration": 5.0
    },
    {
        "text": "like what just general steps about like",
        "start": 2591.72,
        "duration": 5.399
    },
    {
        "text": "things an agent can do and so this",
        "start": 2594.2,
        "duration": 5.28
    },
    {
        "text": "basically I like shows how important it",
        "start": 2597.119,
        "duration": 5.24
    },
    {
        "text": "is to not just treat AI agents in a",
        "start": 2599.48,
        "duration": 4.8
    },
    {
        "text": "vacuum to not think that you know",
        "start": 2602.359,
        "duration": 3.881
    },
    {
        "text": "they're operating without any human",
        "start": 2604.28,
        "duration": 3.88
    },
    {
        "text": "assistance at all and this is an example",
        "start": 2606.24,
        "duration": 4.359
    },
    {
        "text": "of how we can underestimate um the",
        "start": 2608.16,
        "duration": 4.08
    },
    {
        "text": "capabilities of Agents if we don't",
        "start": 2610.599,
        "duration": 3.801
    },
    {
        "text": "involve humans in the loop now of course",
        "start": 2612.24,
        "duration": 3.68
    },
    {
        "text": "human in the loop studies are extremely",
        "start": 2614.4,
        "duration": 3.88
    },
    {
        "text": "expensive there are lots of challenges",
        "start": 2615.92,
        "duration": 4.24
    },
    {
        "text": "to doing them right we have like entire",
        "start": 2618.28,
        "duration": 4.16
    },
    {
        "text": "fields of social science research um",
        "start": 2620.16,
        "duration": 3.959
    },
    {
        "text": "that tell us how we should do these",
        "start": 2622.44,
        "duration": 3.2
    },
    {
        "text": "types of things while still maintaining",
        "start": 2624.119,
        "duration": 3.561
    },
    {
        "text": "validity uh but essentially at the end",
        "start": 2625.64,
        "duration": 3.8
    },
    {
        "text": "of the day if our job is to measure how",
        "start": 2627.68,
        "duration": 3.919
    },
    {
        "text": "well tools work in the real world then",
        "start": 2629.44,
        "duration": 3.72
    },
    {
        "text": "one of the best ways to do that is",
        "start": 2631.599,
        "duration": 3.601
    },
    {
        "text": "through humanin the loop studies very",
        "start": 2633.16,
        "duration": 4.04
    },
    {
        "text": "cool very cool and final question I you",
        "start": 2635.2,
        "duration": 3.72
    },
    {
        "text": "spoke about different levels of agent",
        "start": 2637.2,
        "duration": 4.04
    },
    {
        "text": "generality can can you bring that in",
        "start": 2638.92,
        "duration": 4.6
    },
    {
        "text": "absolutely um so I think when we're",
        "start": 2641.24,
        "duration": 4.52
    },
    {
        "text": "talking about AI agents we might be",
        "start": 2643.52,
        "duration": 3.72
    },
    {
        "text": "talking about very different types of",
        "start": 2645.76,
        "duration": 4.44
    },
    {
        "text": "Agents one example of an AI agent would",
        "start": 2647.24,
        "duration": 5.879
    },
    {
        "text": "be umu agent uh it's an agent also",
        "start": 2650.2,
        "duration": 4.879
    },
    {
        "text": "developed by others at Princeton uh",
        "start": 2653.119,
        "duration": 4.2
    },
    {
        "text": "which aims to solve software engineering",
        "start": 2655.079,
        "duration": 4.841
    },
    {
        "text": "tasks um that are created using GitHub",
        "start": 2657.319,
        "duration": 6.0
    },
    {
        "text": "issues um this is a task specific agent",
        "start": 2659.92,
        "duration": 5.04
    },
    {
        "text": "so there's a specific task that the",
        "start": 2663.319,
        "duration": 3.401
    },
    {
        "text": "agent is made for which is solving",
        "start": 2664.96,
        "duration": 3.44
    },
    {
        "text": "GitHub issues that is given a",
        "start": 2666.72,
        "duration": 4.52
    },
    {
        "text": "description of a particular issue and a",
        "start": 2668.4,
        "duration": 5.24
    },
    {
        "text": "repository make a change to this",
        "start": 2671.24,
        "duration": 4.96
    },
    {
        "text": "repository that fixes this issue then",
        "start": 2673.64,
        "duration": 4.88
    },
    {
        "text": "there have been claims that we have more",
        "start": 2676.2,
        "duration": 4.56
    },
    {
        "text": "General agents so one of the claims that",
        "start": 2678.52,
        "duration": 4.319
    },
    {
        "text": "we've seen repeatedly in the last year",
        "start": 2680.76,
        "duration": 6.12
    },
    {
        "text": "are about domain General agents on the",
        "start": 2682.839,
        "duration": 7.401
    },
    {
        "text": "web uh so these generalist agents can uh",
        "start": 2686.88,
        "duration": 5.479
    },
    {
        "text": "are claimed to operate on the open web",
        "start": 2690.24,
        "duration": 4.28
    },
    {
        "text": "they can essentially do any task on any",
        "start": 2692.359,
        "duration": 4.841
    },
    {
        "text": "given website and uh this is fundament",
        "start": 2694.52,
        "duration": 4.64
    },
    {
        "text": "ly different from sbench because the",
        "start": 2697.2,
        "duration": 4.159
    },
    {
        "text": "tasks now have no structure there is not",
        "start": 2699.16,
        "duration": 4.0
    },
    {
        "text": "like a singular task that an agent must",
        "start": 2701.359,
        "duration": 4.0
    },
    {
        "text": "be able to do rather it needs to learn",
        "start": 2703.16,
        "duration": 4.72
    },
    {
        "text": "to um operate in many different types of",
        "start": 2705.359,
        "duration": 5.041
    },
    {
        "text": "environment and finally at the highest",
        "start": 2707.88,
        "duration": 4.959
    },
    {
        "text": "level uh we have tasks that are",
        "start": 2710.4,
        "duration": 4.679
    },
    {
        "text": "completely General so an agent must be",
        "start": 2712.839,
        "duration": 4.841
    },
    {
        "text": "able to do um let's say tasks related to",
        "start": 2715.079,
        "duration": 4.961
    },
    {
        "text": "the web tasks related to coding tasks",
        "start": 2717.68,
        "duration": 5.28
    },
    {
        "text": "related to robotics um essentially close",
        "start": 2720.04,
        "duration": 5.72
    },
    {
        "text": "to some definitions of AGI where you",
        "start": 2722.96,
        "duration": 4.52
    },
    {
        "text": "know people feel like we have completely",
        "start": 2725.76,
        "duration": 4.52
    },
    {
        "text": "General agents that can do most tasks um",
        "start": 2727.48,
        "duration": 5.56
    },
    {
        "text": "similar to how humans might do them and",
        "start": 2730.28,
        "duration": 4.36
    },
    {
        "text": "at these three different levels of",
        "start": 2733.04,
        "duration": 3.68
    },
    {
        "text": "granularity I think the types of",
        "start": 2734.64,
        "duration": 4.32
    },
    {
        "text": "benchmarks we construct also need to be",
        "start": 2736.72,
        "duration": 4.68
    },
    {
        "text": "extremely different um so for task",
        "start": 2738.96,
        "duration": 5.639
    },
    {
        "text": "specific agents what we really need is",
        "start": 2741.4,
        "duration": 5.679
    },
    {
        "text": "to model how these tasks might change",
        "start": 2744.599,
        "duration": 5.321
    },
    {
        "text": "over time and that's the basis for",
        "start": 2747.079,
        "duration": 5.121
    },
    {
        "text": "actually creating the test set That's",
        "start": 2749.92,
        "duration": 4.72
    },
    {
        "text": "the basis for actually creating like the",
        "start": 2752.2,
        "duration": 5.76
    },
    {
        "text": "evaluations that we use our AI agent on",
        "start": 2754.64,
        "duration": 5.4
    },
    {
        "text": "because if you think about solving tasks",
        "start": 2757.96,
        "duration": 5.119
    },
    {
        "text": "like uh the the sbench series of tasks",
        "start": 2760.04,
        "duration": 5.039
    },
    {
        "text": "it's not like code repository stay",
        "start": 2763.079,
        "duration": 3.961
    },
    {
        "text": "stable over time the types of issues",
        "start": 2765.079,
        "duration": 4.721
    },
    {
        "text": "change languages change in some cases",
        "start": 2767.04,
        "duration": 4.559
    },
    {
        "text": "repositories go out of business other",
        "start": 2769.8,
        "duration": 3.64
    },
    {
        "text": "repositories come in and so what we",
        "start": 2771.599,
        "duration": 4.441
    },
    {
        "text": "really need to model is how well does an",
        "start": 2773.44,
        "duration": 5.119
    },
    {
        "text": "agent um sort of do when these types of",
        "start": 2776.04,
        "duration": 5.16
    },
    {
        "text": "changes are included in the task on the",
        "start": 2778.559,
        "duration": 4.76
    },
    {
        "text": "domain General level we don't just need",
        "start": 2781.2,
        "duration": 4.52
    },
    {
        "text": "different tasks in the heldout test set",
        "start": 2783.319,
        "duration": 4.361
    },
    {
        "text": "but we need like entire websites that",
        "start": 2785.72,
        "duration": 5.16
    },
    {
        "text": "were not for example in the held outet",
        "start": 2787.68,
        "duration": 5.76
    },
    {
        "text": "of a of a web agent Benchmark because",
        "start": 2790.88,
        "duration": 4.12
    },
    {
        "text": "that's the only way in which we can",
        "start": 2793.44,
        "duration": 3.8
    },
    {
        "text": "actually model um how let's say a",
        "start": 2795.0,
        "duration": 3.839
    },
    {
        "text": "generalist web agent would do when",
        "start": 2797.24,
        "duration": 4.04
    },
    {
        "text": "exposed to new types of websites in the",
        "start": 2798.839,
        "duration": 5.361
    },
    {
        "text": "real world now what this also means is",
        "start": 2801.28,
        "duration": 4.559
    },
    {
        "text": "that we need to improve our standards",
        "start": 2804.2,
        "duration": 4.28
    },
    {
        "text": "for how we release benchmarks because",
        "start": 2805.839,
        "duration": 4.52
    },
    {
        "text": "what I'm essentially proposing here is",
        "start": 2808.48,
        "duration": 4.32
    },
    {
        "text": "that a specific portion of the Benchmark",
        "start": 2810.359,
        "duration": 5.041
    },
    {
        "text": "should always remain secret like it's",
        "start": 2812.8,
        "duration": 4.96
    },
    {
        "text": "not just that a certain type or a",
        "start": 2815.4,
        "duration": 4.24
    },
    {
        "text": "certain set of websites is declared to",
        "start": 2817.76,
        "duration": 4.24
    },
    {
        "text": "be the test set it's that we need to",
        "start": 2819.64,
        "duration": 3.84
    },
    {
        "text": "have like a heldout test set that's",
        "start": 2822.0,
        "duration": 3.079
    },
    {
        "text": "completely secret for the duration of",
        "start": 2823.48,
        "duration": 5.359
    },
    {
        "text": "its life um this is the approach that",
        "start": 2825.079,
        "duration": 5.961
    },
    {
        "text": "we've seen fail many times in the ml",
        "start": 2828.839,
        "duration": 3.601
    },
    {
        "text": "Community there's a strong culture of",
        "start": 2831.04,
        "duration": 3.12
    },
    {
        "text": "openness and perhaps rightly so in the",
        "start": 2832.44,
        "duration": 3.72
    },
    {
        "text": "past but I think this is an approach we",
        "start": 2834.16,
        "duration": 4.08
    },
    {
        "text": "have to adopt if you're concerned about",
        "start": 2836.16,
        "duration": 4.6
    },
    {
        "text": "issues like llm contamination where an",
        "start": 2838.24,
        "duration": 4.24
    },
    {
        "text": "llm might literally be trained on the",
        "start": 2840.76,
        "duration": 4.319
    },
    {
        "text": "test data um and therefore overestimates",
        "start": 2842.48,
        "duration": 4.52
    },
    {
        "text": "the performance yeah this is a secret",
        "start": 2845.079,
        "duration": 4.76
    },
    {
        "text": "that France knows all too",
        "start": 2847.0,
        "duration": 5.119
    },
    {
        "text": "well did you have any quick comments on",
        "start": 2849.839,
        "duration": 4.881
    },
    {
        "text": "on the arc challenge um so I think the",
        "start": 2852.119,
        "duration": 4.801
    },
    {
        "text": "arc challenge is very interesting and",
        "start": 2854.72,
        "duration": 4.24
    },
    {
        "text": "fascinating specifically because it",
        "start": 2856.92,
        "duration": 4.28
    },
    {
        "text": "tries to model this type of distribution",
        "start": 2858.96,
        "duration": 5.56
    },
    {
        "text": "shift so uh one of the sort of most",
        "start": 2861.2,
        "duration": 5.32
    },
    {
        "text": "important parts of the paper on the",
        "start": 2864.52,
        "duration": 3.4
    },
    {
        "text": "measure of intelligence that I think is",
        "start": 2866.52,
        "duration": 3.88
    },
    {
        "text": "often buried is that shle comes up with",
        "start": 2867.92,
        "duration": 5.08
    },
    {
        "text": "this entire hierarchy of intelligence um",
        "start": 2870.4,
        "duration": 4.439
    },
    {
        "text": "you know like are you just sort of",
        "start": 2873.0,
        "duration": 4.04
    },
    {
        "text": "learning in distribution examples in",
        "start": 2874.839,
        "duration": 3.52
    },
    {
        "text": "which case I think he would be pretty",
        "start": 2877.04,
        "duration": 4.12
    },
    {
        "text": "optimistic about any system development",
        "start": 2878.359,
        "duration": 4.321
    },
    {
        "text": "happening on that level or are you",
        "start": 2881.16,
        "duration": 3.12
    },
    {
        "text": "learning outter distribution samples and",
        "start": 2882.68,
        "duration": 3.56
    },
    {
        "text": "at what level are these out of",
        "start": 2884.28,
        "duration": 4.68
    },
    {
        "text": "distribution um and I think actually",
        "start": 2886.24,
        "duration": 4.76
    },
    {
        "text": "this paper was a huge inspiration for us",
        "start": 2888.96,
        "duration": 3.44
    },
    {
        "text": "as well when thinking of this hierarchy",
        "start": 2891.0,
        "duration": 4.16
    },
    {
        "text": "of generality when it comes to the arc",
        "start": 2892.4,
        "duration": 5.36
    },
    {
        "text": "um test set specifically I think there",
        "start": 2895.16,
        "duration": 4.199
    },
    {
        "text": "are two types of claims to be made about",
        "start": 2897.76,
        "duration": 3.4
    },
    {
        "text": "it the first type of claim that I've",
        "start": 2899.359,
        "duration": 4.561
    },
    {
        "text": "seen online is that progress on Arc",
        "start": 2901.16,
        "duration": 5.08
    },
    {
        "text": "means progress towards AGI the second",
        "start": 2903.92,
        "duration": 4.48
    },
    {
        "text": "type of claim is that Pro Arc is like",
        "start": 2906.24,
        "duration": 4.76
    },
    {
        "text": "one specific uh domain you can create",
        "start": 2908.4,
        "duration": 4.12
    },
    {
        "text": "like a domain specific language and",
        "start": 2911.0,
        "duration": 3.76
    },
    {
        "text": "actually that's how we've seen uh most",
        "start": 2912.52,
        "duration": 4.2
    },
    {
        "text": "of the leaderboard competitors um do",
        "start": 2914.76,
        "duration": 3.72
    },
    {
        "text": "well on it I lean towards the latter",
        "start": 2916.72,
        "duration": 4.879
    },
    {
        "text": "view I think AGI is um something that is",
        "start": 2918.48,
        "duration": 5.68
    },
    {
        "text": "sort of much more open-ended compared to",
        "start": 2921.599,
        "duration": 5.321
    },
    {
        "text": "even the set of tasks that Arc has so I",
        "start": 2924.16,
        "duration": 5.24
    },
    {
        "text": "mean maybe if progress on Arc is",
        "start": 2926.92,
        "duration": 4.199
    },
    {
        "text": "progress towards like verification",
        "start": 2929.4,
        "duration": 3.56
    },
    {
        "text": "systems that work better and maybe",
        "start": 2931.119,
        "duration": 3.72
    },
    {
        "text": "verification systems and dsls are what",
        "start": 2932.96,
        "duration": 4.119
    },
    {
        "text": "we need for AGI both are both of those",
        "start": 2934.839,
        "duration": 4.561
    },
    {
        "text": "are like relatively ten years claims but",
        "start": 2937.079,
        "duration": 4.561
    },
    {
        "text": "I do think that like Arc is in general",
        "start": 2939.4,
        "duration": 4.24
    },
    {
        "text": "one of the more well-designed benchmarks",
        "start": 2941.64,
        "duration": 3.76
    },
    {
        "text": "and at least when it comes to evaluation",
        "start": 2943.64,
        "duration": 4.28
    },
    {
        "text": "designs we should take a lot of lessons",
        "start": 2945.4,
        "duration": 4.28
    },
    {
        "text": "from how Arc thought about its held",
        "start": 2947.92,
        "duration": 3.72
    },
    {
        "text": "outsets yeah and to be fair shle would",
        "start": 2949.68,
        "duration": 2.96
    },
    {
        "text": "agree with you he thinks it's a",
        "start": 2951.64,
        "duration": 2.6
    },
    {
        "text": "necessary but not sufficient condition I",
        "start": 2952.64,
        "duration": 2.52
    },
    {
        "text": "think there's a difference between",
        "start": 2954.24,
        "duration": 2.8
    },
    {
        "text": "Chalet and the organizers of of the arc",
        "start": 2955.16,
        "duration": 4.919
    },
    {
        "text": "prize but um anyway sash it's been an",
        "start": 2957.04,
        "duration": 4.44
    },
    {
        "text": "absolute honor to have you on this has",
        "start": 2960.079,
        "duration": 3.321
    },
    {
        "text": "been one of my favorite interviews all",
        "start": 2961.48,
        "duration": 4.4
    },
    {
        "text": "week and F Folks at home subscribe to",
        "start": 2963.4,
        "duration": 5.76
    },
    {
        "text": "the AI snake oil substack blog pre-order",
        "start": 2965.88,
        "duration": 6.479
    },
    {
        "text": "the AI snake oil book and thank you so",
        "start": 2969.16,
        "duration": 4.639
    },
    {
        "text": "much for coming on thank you so much for",
        "start": 2972.359,
        "duration": 4.641
    },
    {
        "text": "having me",
        "start": 2973.799,
        "duration": 3.201
    }
]